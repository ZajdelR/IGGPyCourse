

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Lecture 9: Neural Networks &#8212; Python Course; Institute of Geodesy and Geoinformatics; Wroclaw University of Environemntal and Life Sciences</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/vendor/fontawesome/6.1.2/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/vendor/fontawesome/6.5.2/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/copybutton_funcs.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery-3.6.0.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/searchtools.js"></script>
    <script src="../_static/sphinx-thebe.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/underscore-1.13.1.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/scripts/bootstrap.js"></script>
    <script src="../_static/scripts/pydata-sphinx-theme.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js"></script>
    <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_sources/9. AI 9';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../Mod0.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../Mod0.html">
                    Wprowadzenie
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Mod1.html">Moduł 1 - Środowisko Python - 2025/2026</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Mod1_cw.html">Moduł 1 - Ćwiczenia - 2025/2026</a></li>


<li class="toctree-l1"><a class="reference internal" href="../Mod2.html">Moduł 2 - Podstawowe typy danych - 2024/2025</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mod2_cw.html">Moduł 2 - Ćwiczenia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mod3.html">Moduł 3 - Kontrola przepływu 2024/2025</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mod3_cw.html">Moduł 3 - Ćwiczenia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mod4.html">Moduł 4 - Funkcje i typy mapujące - 2024/2025</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mod4_cw.html">Moduł 4 - Ćwiczenia</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Mod5.html">Moduł 5 - Macierze - 2024/2025</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Mod5_cw.html">Moduł 5 - Ćwiczenia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mod6.html">Moduł 6 - Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mod6_cw.html">Moduł 6 - Ćwiczenia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mod7.html">Moduł 7 - Wizualizacje z matplotlibem</a></li>



</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/_sources/9. AI 9.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 9: Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-neural-networks">What Are Neural Networks?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-are-neural-networks-important">Why Are Neural Networks Important?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-they-work-high-level-overview">How Do They Work? (High-Level Overview)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-features">Key Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-are-neural-network-used">Where are Neural Network used?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-blocks-of-a-neural-network">Building Blocks of a Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-data-flows">How Data Flows</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-neural-network-architecture-impacts-predictions">How Neural Network Architecture Impacts Predictions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-layers">1. <strong>Number of Layers</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-neurons-in-each-layer">2. <strong>Number of Neurons in Each Layer</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#choice-of-activation-functions">3. <strong>Choice of Activation Functions</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-techniques">4. <strong>Regularization Techniques</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#depth-vs-breadth">5. <strong>Depth vs. Breadth</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connectivity-and-architecture">6. <strong>Connectivity and Architecture</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary"><strong>Summary</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-activation-functions">Common Activation Functions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sigmoid-function">1. <strong>Sigmoid Function</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relu-rectified-linear-unit">2. <strong>ReLU (Rectified Linear Unit)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tanh-hyperbolic-tangent">3. <strong>Tanh (Hyperbolic Tangent)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-function">4. <strong>Softmax Function</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#leaky-relu">5. <strong>Leaky ReLU</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-an-activation-function"><strong>Choosing an Activation Function</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-neural-networks-learn">How Neural Networks Learn</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-propagation">1. <strong>Forward Propagation</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">2. <strong>Loss Function</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation">3. <strong>Backpropagation</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iterative-learning">4. <strong>Iterative Learning</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">5. <strong>Key Concepts</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-of-forward-propagation">Example of Forward Propagation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weights-and-biases">Weights and Biases</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-calculation">Step-by-Step Calculation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#inputs">1. <strong>Inputs</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hidden-layer-calculations">2. <strong>Hidden Layer Calculations</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#output-layer-calculation">3. <strong>Output Layer Calculation</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-values">4. <strong>Example Values</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-output">Final Output</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Backpropagation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-neural-network-architectures-rnns-and-cnns">Advanced Neural Network Architectures: RNNs and CNNs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-neural-networks-cnns">1. <strong>Convolutional Neural Networks (CNNs)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-components">Key Components:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-architecture">Example Architecture:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#use-cases">Use Cases:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-neural-networks-rnns">2. <strong>Recurrent Neural Networks (RNNs)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Key Components:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Example Architecture:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Use Cases:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differences-between-cnns-and-rnns">3. <strong>Differences Between CNNs and RNNs</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#combined-architectures">4. <strong>Combined Architectures</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-limitations-of-neural-networks">Challenges and Limitations of Neural Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-requirements">1. <strong>Data Requirements</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-cost">2. <strong>Computational Cost</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting">3. <strong>Overfitting</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#black-box-nature">4. <strong>Black Box Nature</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-sensitivity">5. <strong>Hyperparameter Sensitivity</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#energy-consumption">6. <strong>Energy Consumption</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Summary</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-9-neural-networks">
<h1>Lecture 9: Neural Networks<a class="headerlink" href="#lecture-9-neural-networks" title="Permalink to this heading">#</a></h1>
<p><strong>Introduction to Neural Networks</strong></p>
<img src='img/brain.png'/>
<section id="what-are-neural-networks">
<h2>What Are Neural Networks?<a class="headerlink" href="#what-are-neural-networks" title="Permalink to this heading">#</a></h2>
<p>Neural networks are a type of machine learning model inspired by the structure and function of the human brain. Just as our brain processes information through interconnected neurons, neural networks process data through layers of interconnected nodes, called artificial neurons.</p>
</section>
<section id="why-are-neural-networks-important">
<h2>Why Are Neural Networks Important?<a class="headerlink" href="#why-are-neural-networks-important" title="Permalink to this heading">#</a></h2>
<p>Neural networks are powerful tools for solving complex problems. They are behind many modern technologies we use daily, such as:</p>
<ul class="simple">
<li><p><strong>Image Recognition</strong>: Identifying objects, faces, or text in images.</p></li>
<li><p><strong>Language Translation</strong>: Converting text from one language to another (e.g., Google Translate).</p></li>
<li><p><strong>Autonomous Vehicles</strong>: Helping cars understand and react to their surroundings.</p></li>
</ul>
</section>
<section id="how-do-they-work-high-level-overview">
<h2>How Do They Work? (High-Level Overview)<a class="headerlink" href="#how-do-they-work-high-level-overview" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Inputs</strong>: Data enters the network through input neurons.</p></li>
<li><p><strong>Processing</strong>: Data moves through layers of neurons, which apply mathematical operations and transformations.</p></li>
<li><p><strong>Outputs</strong>: The final layer produces predictions or decisions based on the input data.</p></li>
</ol>
<p>For example, imagine teaching a neural network to recognize handwritten numbers. You show it images of digits, and over time, it learns patterns to correctly identify them, much like a child learns to read numbers.</p>
</section>
<section id="key-features">
<h2>Key Features<a class="headerlink" href="#key-features" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Learning from Data</strong>: Neural networks improve their performance as they are exposed to more examples.</p></li>
<li><p><strong>Adaptability</strong>: They can solve diverse problems, from diagnosing diseases to generating realistic images.</p></li>
</ul>
</section>
<section id="where-are-neural-network-used">
<h2>Where are Neural Network used?<a class="headerlink" href="#where-are-neural-network-used" title="Permalink to this heading">#</a></h2>
<p>Medical Imaging: Neural networks are used for diagnosing diseases by analyzing medical images, such as detection of brain tumor on MRIs.</p>
<p>Drug Discovery: DeepMind’s AlphaFold predicts protein folding with high accuracy, aiding drug development.</p>
<p>Driving Systems: Tesla’s Autopilot uses neural networks to detect lanes, recognize traffic signs, and avoid obstacles.</p>
<p>Language Translation: Google Translate uses transformer-based neural networks like BERT for highly accurate translations.</p>
<p>Chatbots and Virtual Assistants: OpenAI’s GPT models, including ChatGPT, are based on neural networks.</p>
<p>Finance: PayPal uses neural networks to detect anomalous behaviors in financial transactions.</p>
<p>Credit scoring: Neural networks analyze credit history and financial data for personalized lending.</p>
<p>Wildlife conservation: Conservation organizations use neural networks to identify species and track movements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.widgets</span> <span class="kn">import</span> <span class="n">Slider</span>
<span class="o">%</span><span class="k">matplotlib</span> notebook
<span class="k">def</span> <span class="nf">draw_neural_net</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">layer_sizes</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Draws a neural network diagram.</span>
<span class="sd">    Args:</span>
<span class="sd">        ax: matplotlib axis to draw on.</span>
<span class="sd">        layer_sizes: List with the number of neurons in each layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

    <span class="c1"># Define spacing for layers and neurons</span>
    <span class="n">v_spacing</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">))</span>  <span class="c1"># Vertical spacing</span>
    <span class="n">h_spacing</span> <span class="o">=</span> <span class="mf">0.9</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Horizontal spacing</span>

    <span class="c1"># Draw nodes</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer_size</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layer_size</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">h_spacing</span> <span class="o">+</span> <span class="mf">0.05</span>  <span class="c1"># Horizontal position</span>
            <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">v_spacing</span> <span class="o">+</span> <span class="n">v_spacing</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Vertical position</span>
            <span class="n">circle</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Circle</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">v_spacing</span> <span class="o">/</span> <span class="mf">4.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">circle</span><span class="p">)</span>

    <span class="c1"># Draw edges</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer_size_a</span><span class="p">,</span> <span class="n">layer_size_b</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layer_size_a</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layer_size_b</span><span class="p">):</span>
                <span class="n">x_start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">h_spacing</span> <span class="o">+</span> <span class="mf">0.05</span>
                <span class="n">y_start</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">v_spacing</span> <span class="o">+</span> <span class="n">v_spacing</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">x_end</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">h_spacing</span> <span class="o">+</span> <span class="mf">0.05</span>
                <span class="n">y_end</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">k</span> <span class="o">*</span> <span class="n">v_spacing</span> <span class="o">+</span> <span class="n">v_spacing</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">line</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Line2D</span><span class="p">([</span><span class="n">x_start</span><span class="p">,</span> <span class="n">x_end</span><span class="p">],</span> <span class="p">[</span><span class="n">y_start</span><span class="p">,</span> <span class="n">y_end</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

<span class="c1"># Initial configuration</span>
<span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">draw_neural_net</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">layer_sizes</span><span class="p">)</span>

<span class="c1"># Slider for adjusting the number of hidden layers</span>
<span class="n">ax_slider</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;lightgoldenrodyellow&quot;</span><span class="p">)</span>
<span class="n">slider</span> <span class="o">=</span> <span class="n">Slider</span><span class="p">(</span><span class="n">ax_slider</span><span class="p">,</span> <span class="s2">&quot;Hidden Layers&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">valinit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">valstep</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
    <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">slider</span><span class="o">.</span><span class="n">val</span><span class="p">)</span>
    <span class="n">layer_sizes_new</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">5</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_hidden_layers</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># Input, hidden, output</span>
    <span class="n">draw_neural_net</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">layer_sizes_new</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw_idle</span><span class="p">()</span>

<span class="n">slider</span><span class="o">.</span><span class="n">on_changed</span><span class="p">(</span><span class="n">update</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">/* Put everything inside the global mpl namespace */
/* global mpl */
window.mpl = {};

mpl.get_websocket_type = function () {
    if (typeof WebSocket !== 'undefined') {
        return WebSocket;
    } else if (typeof MozWebSocket !== 'undefined') {
        return MozWebSocket;
    } else {
        alert(
            'Your browser does not have WebSocket support. ' +
                'Please try Chrome, Safari or Firefox ≥ 6. ' +
                'Firefox 4 and 5 are also supported but you ' +
                'have to enable WebSockets in about:config.'
        );
    }
};

mpl.figure = function (figure_id, websocket, ondownload, parent_element) {
    this.id = figure_id;

    this.ws = websocket;

    this.supports_binary = this.ws.binaryType !== undefined;

    if (!this.supports_binary) {
        var warnings = document.getElementById('mpl-warnings');
        if (warnings) {
            warnings.style.display = 'block';
            warnings.textContent =
                'This browser does not support binary websocket messages. ' +
                'Performance may be slow.';
        }
    }

    this.imageObj = new Image();

    this.context = undefined;
    this.message = undefined;
    this.canvas = undefined;
    this.rubberband_canvas = undefined;
    this.rubberband_context = undefined;
    this.format_dropdown = undefined;

    this.image_mode = 'full';

    this.root = document.createElement('div');
    this.root.setAttribute('style', 'display: inline-block');
    this._root_extra_style(this.root);

    parent_element.appendChild(this.root);

    this._init_header(this);
    this._init_canvas(this);
    this._init_toolbar(this);

    var fig = this;

    this.waiting = false;

    this.ws.onopen = function () {
        fig.send_message('supports_binary', { value: fig.supports_binary });
        fig.send_message('send_image_mode', {});
        if (fig.ratio !== 1) {
            fig.send_message('set_device_pixel_ratio', {
                device_pixel_ratio: fig.ratio,
            });
        }
        fig.send_message('refresh', {});
    };

    this.imageObj.onload = function () {
        if (fig.image_mode === 'full') {
            // Full images could contain transparency (where diff images
            // almost always do), so we need to clear the canvas so that
            // there is no ghosting.
            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);
        }
        fig.context.drawImage(fig.imageObj, 0, 0);
    };

    this.imageObj.onunload = function () {
        fig.ws.close();
    };

    this.ws.onmessage = this._make_on_message_function(this);

    this.ondownload = ondownload;
};

mpl.figure.prototype._init_header = function () {
    var titlebar = document.createElement('div');
    titlebar.classList =
        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';
    var titletext = document.createElement('div');
    titletext.classList = 'ui-dialog-title';
    titletext.setAttribute(
        'style',
        'width: 100%; text-align: center; padding: 3px;'
    );
    titlebar.appendChild(titletext);
    this.root.appendChild(titlebar);
    this.header = titletext;
};

mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};

mpl.figure.prototype._root_extra_style = function (_canvas_div) {};

mpl.figure.prototype._init_canvas = function () {
    var fig = this;

    var canvas_div = (this.canvas_div = document.createElement('div'));
    canvas_div.setAttribute('tabindex', '0');
    canvas_div.setAttribute(
        'style',
        'border: 1px solid #ddd;' +
            'box-sizing: content-box;' +
            'clear: both;' +
            'min-height: 1px;' +
            'min-width: 1px;' +
            'outline: 0;' +
            'overflow: hidden;' +
            'position: relative;' +
            'resize: both;' +
            'z-index: 2;'
    );

    function on_keyboard_event_closure(name) {
        return function (event) {
            return fig.key_event(event, name);
        };
    }

    canvas_div.addEventListener(
        'keydown',
        on_keyboard_event_closure('key_press')
    );
    canvas_div.addEventListener(
        'keyup',
        on_keyboard_event_closure('key_release')
    );

    this._canvas_extra_style(canvas_div);
    this.root.appendChild(canvas_div);

    var canvas = (this.canvas = document.createElement('canvas'));
    canvas.classList.add('mpl-canvas');
    canvas.setAttribute(
        'style',
        'box-sizing: content-box;' +
            'pointer-events: none;' +
            'position: relative;' +
            'z-index: 0;'
    );

    this.context = canvas.getContext('2d');

    var backingStore =
        this.context.backingStorePixelRatio ||
        this.context.webkitBackingStorePixelRatio ||
        this.context.mozBackingStorePixelRatio ||
        this.context.msBackingStorePixelRatio ||
        this.context.oBackingStorePixelRatio ||
        this.context.backingStorePixelRatio ||
        1;

    this.ratio = (window.devicePixelRatio || 1) / backingStore;

    var rubberband_canvas = (this.rubberband_canvas = document.createElement(
        'canvas'
    ));
    rubberband_canvas.setAttribute(
        'style',
        'box-sizing: content-box;' +
            'left: 0;' +
            'pointer-events: none;' +
            'position: absolute;' +
            'top: 0;' +
            'z-index: 1;'
    );

    // Apply a ponyfill if ResizeObserver is not implemented by browser.
    if (this.ResizeObserver === undefined) {
        if (window.ResizeObserver !== undefined) {
            this.ResizeObserver = window.ResizeObserver;
        } else {
            var obs = _JSXTOOLS_RESIZE_OBSERVER({});
            this.ResizeObserver = obs.ResizeObserver;
        }
    }

    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {
        var nentries = entries.length;
        for (var i = 0; i < nentries; i++) {
            var entry = entries[i];
            var width, height;
            if (entry.contentBoxSize) {
                if (entry.contentBoxSize instanceof Array) {
                    // Chrome 84 implements new version of spec.
                    width = entry.contentBoxSize[0].inlineSize;
                    height = entry.contentBoxSize[0].blockSize;
                } else {
                    // Firefox implements old version of spec.
                    width = entry.contentBoxSize.inlineSize;
                    height = entry.contentBoxSize.blockSize;
                }
            } else {
                // Chrome <84 implements even older version of spec.
                width = entry.contentRect.width;
                height = entry.contentRect.height;
            }

            // Keep the size of the canvas and rubber band canvas in sync with
            // the canvas container.
            if (entry.devicePixelContentBoxSize) {
                // Chrome 84 implements new version of spec.
                canvas.setAttribute(
                    'width',
                    entry.devicePixelContentBoxSize[0].inlineSize
                );
                canvas.setAttribute(
                    'height',
                    entry.devicePixelContentBoxSize[0].blockSize
                );
            } else {
                canvas.setAttribute('width', width * fig.ratio);
                canvas.setAttribute('height', height * fig.ratio);
            }
            /* This rescales the canvas back to display pixels, so that it
             * appears correct on HiDPI screens. */
            canvas.style.width = width + 'px';
            canvas.style.height = height + 'px';

            rubberband_canvas.setAttribute('width', width);
            rubberband_canvas.setAttribute('height', height);

            // And update the size in Python. We ignore the initial 0/0 size
            // that occurs as the element is placed into the DOM, which should
            // otherwise not happen due to the minimum size styling.
            if (fig.ws.readyState == 1 && width != 0 && height != 0) {
                fig.request_resize(width, height);
            }
        }
    });
    this.resizeObserverInstance.observe(canvas_div);

    function on_mouse_event_closure(name) {
        /* User Agent sniffing is bad, but WebKit is busted:
         * https://bugs.webkit.org/show_bug.cgi?id=144526
         * https://bugs.webkit.org/show_bug.cgi?id=181818
         * The worst that happens here is that they get an extra browser
         * selection when dragging, if this check fails to catch them.
         */
        var UA = navigator.userAgent;
        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);
        if(isWebKit) {
            return function (event) {
                /* This prevents the web browser from automatically changing to
                 * the text insertion cursor when the button is pressed. We
                 * want to control all of the cursor setting manually through
                 * the 'cursor' event from matplotlib */
                event.preventDefault()
                return fig.mouse_event(event, name);
            };
        } else {
            return function (event) {
                return fig.mouse_event(event, name);
            };
        }
    }

    canvas_div.addEventListener(
        'mousedown',
        on_mouse_event_closure('button_press')
    );
    canvas_div.addEventListener(
        'mouseup',
        on_mouse_event_closure('button_release')
    );
    canvas_div.addEventListener(
        'dblclick',
        on_mouse_event_closure('dblclick')
    );
    // Throttle sequential mouse events to 1 every 20ms.
    canvas_div.addEventListener(
        'mousemove',
        on_mouse_event_closure('motion_notify')
    );

    canvas_div.addEventListener(
        'mouseenter',
        on_mouse_event_closure('figure_enter')
    );
    canvas_div.addEventListener(
        'mouseleave',
        on_mouse_event_closure('figure_leave')
    );

    canvas_div.addEventListener('wheel', function (event) {
        if (event.deltaY < 0) {
            event.step = 1;
        } else {
            event.step = -1;
        }
        on_mouse_event_closure('scroll')(event);
    });

    canvas_div.appendChild(canvas);
    canvas_div.appendChild(rubberband_canvas);

    this.rubberband_context = rubberband_canvas.getContext('2d');
    this.rubberband_context.strokeStyle = '#000000';

    this._resize_canvas = function (width, height, forward) {
        if (forward) {
            canvas_div.style.width = width + 'px';
            canvas_div.style.height = height + 'px';
        }
    };

    // Disable right mouse context menu.
    canvas_div.addEventListener('contextmenu', function (_e) {
        event.preventDefault();
        return false;
    });

    function set_focus() {
        canvas.focus();
        canvas_div.focus();
    }

    window.setTimeout(set_focus, 100);
};

mpl.figure.prototype._init_toolbar = function () {
    var fig = this;

    var toolbar = document.createElement('div');
    toolbar.classList = 'mpl-toolbar';
    this.root.appendChild(toolbar);

    function on_click_closure(name) {
        return function (_event) {
            return fig.toolbar_button_onclick(name);
        };
    }

    function on_mouseover_closure(tooltip) {
        return function (event) {
            if (!event.currentTarget.disabled) {
                return fig.toolbar_button_onmouseover(tooltip);
            }
        };
    }

    fig.buttons = {};
    var buttonGroup = document.createElement('div');
    buttonGroup.classList = 'mpl-button-group';
    for (var toolbar_ind in mpl.toolbar_items) {
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) {
            /* Instead of a spacer, we start a new button group. */
            if (buttonGroup.hasChildNodes()) {
                toolbar.appendChild(buttonGroup);
            }
            buttonGroup = document.createElement('div');
            buttonGroup.classList = 'mpl-button-group';
            continue;
        }

        var button = (fig.buttons[name] = document.createElement('button'));
        button.classList = 'mpl-widget';
        button.setAttribute('role', 'button');
        button.setAttribute('aria-disabled', 'false');
        button.addEventListener('click', on_click_closure(method_name));
        button.addEventListener('mouseover', on_mouseover_closure(tooltip));

        var icon_img = document.createElement('img');
        icon_img.src = '_images/' + image + '.png';
        icon_img.srcset = '_images/' + image + '_large.png 2x';
        icon_img.alt = tooltip;
        button.appendChild(icon_img);

        buttonGroup.appendChild(button);
    }

    if (buttonGroup.hasChildNodes()) {
        toolbar.appendChild(buttonGroup);
    }

    var fmt_picker = document.createElement('select');
    fmt_picker.classList = 'mpl-widget';
    toolbar.appendChild(fmt_picker);
    this.format_dropdown = fmt_picker;

    for (var ind in mpl.extensions) {
        var fmt = mpl.extensions[ind];
        var option = document.createElement('option');
        option.selected = fmt === mpl.default_extension;
        option.innerHTML = fmt;
        fmt_picker.appendChild(option);
    }

    var status_bar = document.createElement('span');
    status_bar.classList = 'mpl-message';
    toolbar.appendChild(status_bar);
    this.message = status_bar;
};

mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {
    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,
    // which will in turn request a refresh of the image.
    this.send_message('resize', { width: x_pixels, height: y_pixels });
};

mpl.figure.prototype.send_message = function (type, properties) {
    properties['type'] = type;
    properties['figure_id'] = this.id;
    this.ws.send(JSON.stringify(properties));
};

mpl.figure.prototype.send_draw_message = function () {
    if (!this.waiting) {
        this.waiting = true;
        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));
    }
};

mpl.figure.prototype.handle_save = function (fig, _msg) {
    var format_dropdown = fig.format_dropdown;
    var format = format_dropdown.options[format_dropdown.selectedIndex].value;
    fig.ondownload(fig, format);
};

mpl.figure.prototype.handle_resize = function (fig, msg) {
    var size = msg['size'];
    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {
        fig._resize_canvas(size[0], size[1], msg['forward']);
        fig.send_message('refresh', {});
    }
};

mpl.figure.prototype.handle_rubberband = function (fig, msg) {
    var x0 = msg['x0'] / fig.ratio;
    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;
    var x1 = msg['x1'] / fig.ratio;
    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;
    x0 = Math.floor(x0) + 0.5;
    y0 = Math.floor(y0) + 0.5;
    x1 = Math.floor(x1) + 0.5;
    y1 = Math.floor(y1) + 0.5;
    var min_x = Math.min(x0, x1);
    var min_y = Math.min(y0, y1);
    var width = Math.abs(x1 - x0);
    var height = Math.abs(y1 - y0);

    fig.rubberband_context.clearRect(
        0,
        0,
        fig.canvas.width / fig.ratio,
        fig.canvas.height / fig.ratio
    );

    fig.rubberband_context.strokeRect(min_x, min_y, width, height);
};

mpl.figure.prototype.handle_figure_label = function (fig, msg) {
    // Updates the figure title.
    fig.header.textContent = msg['label'];
};

mpl.figure.prototype.handle_cursor = function (fig, msg) {
    fig.canvas_div.style.cursor = msg['cursor'];
};

mpl.figure.prototype.handle_message = function (fig, msg) {
    fig.message.textContent = msg['message'];
};

mpl.figure.prototype.handle_draw = function (fig, _msg) {
    // Request the server to send over a new figure.
    fig.send_draw_message();
};

mpl.figure.prototype.handle_image_mode = function (fig, msg) {
    fig.image_mode = msg['mode'];
};

mpl.figure.prototype.handle_history_buttons = function (fig, msg) {
    for (var key in msg) {
        if (!(key in fig.buttons)) {
            continue;
        }
        fig.buttons[key].disabled = !msg[key];
        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);
    }
};

mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {
    if (msg['mode'] === 'PAN') {
        fig.buttons['Pan'].classList.add('active');
        fig.buttons['Zoom'].classList.remove('active');
    } else if (msg['mode'] === 'ZOOM') {
        fig.buttons['Pan'].classList.remove('active');
        fig.buttons['Zoom'].classList.add('active');
    } else {
        fig.buttons['Pan'].classList.remove('active');
        fig.buttons['Zoom'].classList.remove('active');
    }
};

mpl.figure.prototype.updated_canvas_event = function () {
    // Called whenever the canvas gets updated.
    this.send_message('ack', {});
};

// A function to construct a web socket function for onmessage handling.
// Called in the figure constructor.
mpl.figure.prototype._make_on_message_function = function (fig) {
    return function socket_on_message(evt) {
        if (evt.data instanceof Blob) {
            var img = evt.data;
            if (img.type !== 'image/png') {
                /* FIXME: We get "Resource interpreted as Image but
                 * transferred with MIME type text/plain:" errors on
                 * Chrome.  But how to set the MIME type?  It doesn't seem
                 * to be part of the websocket stream */
                img.type = 'image/png';
            }

            /* Free the memory for the previous frames */
            if (fig.imageObj.src) {
                (window.URL || window.webkitURL).revokeObjectURL(
                    fig.imageObj.src
                );
            }

            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(
                img
            );
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        } else if (
            typeof evt.data === 'string' &&
            evt.data.slice(0, 21) === 'data:image/png;base64'
        ) {
            fig.imageObj.src = evt.data;
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        }

        var msg = JSON.parse(evt.data);
        var msg_type = msg['type'];

        // Call the  "handle_{type}" callback, which takes
        // the figure and JSON message as its only arguments.
        try {
            var callback = fig['handle_' + msg_type];
        } catch (e) {
            console.log(
                "No handler for the '" + msg_type + "' message type: ",
                msg
            );
            return;
        }

        if (callback) {
            try {
                // console.log("Handling '" + msg_type + "' message: ", msg);
                callback(fig, msg);
            } catch (e) {
                console.log(
                    "Exception inside the 'handler_" + msg_type + "' callback:",
                    e,
                    e.stack,
                    msg
                );
            }
        }
    };
};

function getModifiers(event) {
    var mods = [];
    if (event.ctrlKey) {
        mods.push('ctrl');
    }
    if (event.altKey) {
        mods.push('alt');
    }
    if (event.shiftKey) {
        mods.push('shift');
    }
    if (event.metaKey) {
        mods.push('meta');
    }
    return mods;
}

/*
 * return a copy of an object with only non-object keys
 * we need this to avoid circular references
 * https://stackoverflow.com/a/24161582/3208463
 */
function simpleKeys(original) {
    return Object.keys(original).reduce(function (obj, key) {
        if (typeof original[key] !== 'object') {
            obj[key] = original[key];
        }
        return obj;
    }, {});
}

mpl.figure.prototype.mouse_event = function (event, name) {
    if (name === 'button_press') {
        this.canvas.focus();
        this.canvas_div.focus();
    }

    // from https://stackoverflow.com/q/1114465
    var boundingRect = this.canvas.getBoundingClientRect();
    var x = (event.clientX - boundingRect.left) * this.ratio;
    var y = (event.clientY - boundingRect.top) * this.ratio;

    this.send_message(name, {
        x: x,
        y: y,
        button: event.button,
        step: event.step,
        modifiers: getModifiers(event),
        guiEvent: simpleKeys(event),
    });

    return false;
};

mpl.figure.prototype._key_event_extra = function (_event, _name) {
    // Handle any extra behaviour associated with a key event
};

mpl.figure.prototype.key_event = function (event, name) {
    // Prevent repeat events
    if (name === 'key_press') {
        if (event.key === this._key) {
            return;
        } else {
            this._key = event.key;
        }
    }
    if (name === 'key_release') {
        this._key = null;
    }

    var value = '';
    if (event.ctrlKey && event.key !== 'Control') {
        value += 'ctrl+';
    }
    else if (event.altKey && event.key !== 'Alt') {
        value += 'alt+';
    }
    else if (event.shiftKey && event.key !== 'Shift') {
        value += 'shift+';
    }

    value += 'k' + event.key;

    this._key_event_extra(event, name);

    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });
    return false;
};

mpl.figure.prototype.toolbar_button_onclick = function (name) {
    if (name === 'download') {
        this.handle_save(this, null);
    } else {
        this.send_message('toolbar_button', { name: name });
    }
};

mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {
    this.message.textContent = tooltip;
};

///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////
// prettier-ignore
var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError("Constructor requires 'new' operator");i.set(this,e)}function h(){throw new TypeError("Function is not a constructor")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line
mpl.toolbar_items = [["Home", "Reset original view", "fa fa-home", "home"], ["Back", "Back to previous view", "fa fa-arrow-left", "back"], ["Forward", "Forward to next view", "fa fa-arrow-right", "forward"], ["", "", "", ""], ["Pan", "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect", "fa fa-arrows", "pan"], ["Zoom", "Zoom to rectangle\nx/y fixes axis", "fa fa-square-o", "zoom"], ["", "", "", ""], ["Download", "Download plot", "fa fa-floppy-o", "download"]];

mpl.extensions = ["eps", "jpeg", "pgf", "pdf", "png", "ps", "raw", "svg", "tif", "webp"];

mpl.default_extension = "png";/* global mpl */

var comm_websocket_adapter = function (comm) {
    // Create a "websocket"-like object which calls the given IPython comm
    // object with the appropriate methods. Currently this is a non binary
    // socket, so there is still some room for performance tuning.
    var ws = {};

    ws.binaryType = comm.kernel.ws.binaryType;
    ws.readyState = comm.kernel.ws.readyState;
    function updateReadyState(_event) {
        if (comm.kernel.ws) {
            ws.readyState = comm.kernel.ws.readyState;
        } else {
            ws.readyState = 3; // Closed state.
        }
    }
    comm.kernel.ws.addEventListener('open', updateReadyState);
    comm.kernel.ws.addEventListener('close', updateReadyState);
    comm.kernel.ws.addEventListener('error', updateReadyState);

    ws.close = function () {
        comm.close();
    };
    ws.send = function (m) {
        //console.log('sending', m);
        comm.send(m);
    };
    // Register the callback with on_msg.
    comm.on_msg(function (msg) {
        //console.log('receiving', msg['content']['data'], msg);
        var data = msg['content']['data'];
        if (data['blob'] !== undefined) {
            data = {
                data: new Blob(msg['buffers'], { type: data['blob'] }),
            };
        }
        // Pass the mpl event to the overridden (by mpl) onmessage function.
        ws.onmessage(data);
    });
    return ws;
};

mpl.mpl_figure_comm = function (comm, msg) {
    // This is the function which gets called when the mpl process
    // starts-up an IPython Comm through the "matplotlib" channel.

    var id = msg.content.data.id;
    // Get hold of the div created by the display call when the Comm
    // socket was opened in Python.
    var element = document.getElementById(id);
    var ws_proxy = comm_websocket_adapter(comm);

    function ondownload(figure, _format) {
        window.open(figure.canvas.toDataURL());
    }

    var fig = new mpl.figure(id, ws_proxy, ondownload, element);

    // Call onopen now - mpl needs it, as it is assuming we've passed it a real
    // web socket which is closed, not our websocket->open comm proxy.
    ws_proxy.onopen();

    fig.parent_element = element;
    fig.cell_info = mpl.find_output_cell("<div id='" + id + "'></div>");
    if (!fig.cell_info) {
        console.error('Failed to find cell for figure', id, fig);
        return;
    }
    fig.cell_info[0].output_area.element.on(
        'cleared',
        { fig: fig },
        fig._remove_fig_handler
    );
};

mpl.figure.prototype.handle_close = function (fig, msg) {
    var width = fig.canvas.width / fig.ratio;
    fig.cell_info[0].output_area.element.off(
        'cleared',
        fig._remove_fig_handler
    );
    fig.resizeObserverInstance.unobserve(fig.canvas_div);

    // Update the output cell to use the data from the current canvas.
    fig.push_to_output();
    var dataURL = fig.canvas.toDataURL();
    // Re-enable the keyboard manager in IPython - without this line, in FF,
    // the notebook keyboard shortcuts fail.
    IPython.keyboard_manager.enable();
    fig.parent_element.innerHTML =
        '<img src="' + dataURL + '" width="' + width + '">';
    fig.close_ws(fig, msg);
};

mpl.figure.prototype.close_ws = function (fig, msg) {
    fig.send_message('closing', msg);
    // fig.ws.close()
};

mpl.figure.prototype.push_to_output = function (_remove_interactive) {
    // Turn the data on the canvas into data in the output cell.
    var width = this.canvas.width / this.ratio;
    var dataURL = this.canvas.toDataURL();
    this.cell_info[1]['text/html'] =
        '<img src="' + dataURL + '" width="' + width + '">';
};

mpl.figure.prototype.updated_canvas_event = function () {
    // Tell IPython that the notebook contents must change.
    IPython.notebook.set_dirty(true);
    this.send_message('ack', {});
    var fig = this;
    // Wait a second, then push the new image to the DOM so
    // that it is saved nicely (might be nice to debounce this).
    setTimeout(function () {
        fig.push_to_output();
    }, 1000);
};

mpl.figure.prototype._init_toolbar = function () {
    var fig = this;

    var toolbar = document.createElement('div');
    toolbar.classList = 'btn-toolbar';
    this.root.appendChild(toolbar);

    function on_click_closure(name) {
        return function (_event) {
            return fig.toolbar_button_onclick(name);
        };
    }

    function on_mouseover_closure(tooltip) {
        return function (event) {
            if (!event.currentTarget.disabled) {
                return fig.toolbar_button_onmouseover(tooltip);
            }
        };
    }

    fig.buttons = {};
    var buttonGroup = document.createElement('div');
    buttonGroup.classList = 'btn-group';
    var button;
    for (var toolbar_ind in mpl.toolbar_items) {
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) {
            /* Instead of a spacer, we start a new button group. */
            if (buttonGroup.hasChildNodes()) {
                toolbar.appendChild(buttonGroup);
            }
            buttonGroup = document.createElement('div');
            buttonGroup.classList = 'btn-group';
            continue;
        }

        button = fig.buttons[name] = document.createElement('button');
        button.classList = 'btn btn-default';
        button.href = '#';
        button.title = name;
        button.innerHTML = '<i class="fa ' + image + ' fa-lg"></i>';
        button.addEventListener('click', on_click_closure(method_name));
        button.addEventListener('mouseover', on_mouseover_closure(tooltip));
        buttonGroup.appendChild(button);
    }

    if (buttonGroup.hasChildNodes()) {
        toolbar.appendChild(buttonGroup);
    }

    // Add the status bar.
    var status_bar = document.createElement('span');
    status_bar.classList = 'mpl-message pull-right';
    toolbar.appendChild(status_bar);
    this.message = status_bar;

    // Add the close button to the window.
    var buttongrp = document.createElement('div');
    buttongrp.classList = 'btn-group inline pull-right';
    button = document.createElement('button');
    button.classList = 'btn btn-mini btn-primary';
    button.href = '#';
    button.title = 'Stop Interaction';
    button.innerHTML = '<i class="fa fa-power-off icon-remove icon-large"></i>';
    button.addEventListener('click', function (_evt) {
        fig.handle_close(fig, {});
    });
    button.addEventListener(
        'mouseover',
        on_mouseover_closure('Stop Interaction')
    );
    buttongrp.appendChild(button);
    var titlebar = this.root.querySelector('.ui-dialog-titlebar');
    titlebar.insertBefore(buttongrp, titlebar.firstChild);
};

mpl.figure.prototype._remove_fig_handler = function (event) {
    var fig = event.data.fig;
    if (event.target !== this) {
        // Ignore bubbled events from children.
        return;
    }
    fig.close_ws(fig, {});
};

mpl.figure.prototype._root_extra_style = function (el) {
    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.
};

mpl.figure.prototype._canvas_extra_style = function (el) {
    // this is important to make the div 'focusable
    el.setAttribute('tabindex', 0);
    // reach out to IPython and tell the keyboard manager to turn it's self
    // off when our div gets focus

    // location in version 3
    if (IPython.notebook.keyboard_manager) {
        IPython.notebook.keyboard_manager.register_events(el);
    } else {
        // location in version 2
        IPython.keyboard_manager.register_events(el);
    }
};

mpl.figure.prototype._key_event_extra = function (event, _name) {
    // Check for shift+enter
    if (event.shiftKey && event.which === 13) {
        this.canvas_div.blur();
        // select the cell after this one
        var index = IPython.notebook.find_cell_index(this.cell_info[0]);
        IPython.notebook.select(index + 1);
    }
};

mpl.figure.prototype.handle_save = function (fig, _msg) {
    fig.ondownload(fig, null);
};

mpl.find_output_cell = function (html_output) {
    // Return the cell and output element which can be found *uniquely* in the notebook.
    // Note - this is a bit hacky, but it is done because the "notebook_saving.Notebook"
    // IPython event is triggered only after the cells have been serialised, which for
    // our purposes (turning an active figure into a static one), is too late.
    var cells = IPython.notebook.get_cells();
    var ncells = cells.length;
    for (var i = 0; i < ncells; i++) {
        var cell = cells[i];
        if (cell.cell_type === 'code') {
            for (var j = 0; j < cell.output_area.outputs.length; j++) {
                var data = cell.output_area.outputs[j];
                if (data.data) {
                    // IPython >= 3 moved mimebundle to data attribute of output
                    data = data.data;
                }
                if (data['text/html'] === html_output) {
                    return [cell, data, j];
                }
            }
        }
    }
};

// Register the function which deals with the matplotlib target/channel.
// The kernel may be null if the page has been refreshed.
if (IPython.notebook.kernel !== null) {
    IPython.notebook.kernel.comm_manager.register_target(
        'matplotlib',
        mpl.mpl_figure_comm
    );
}
</script><div class="output text_html"><div id='323fbe66-7f0b-48fa-b534-b986c2cf013c'></div></div></div>
</div>
<p><strong>The Anatomy of a Neural Network</strong></p>
</section>
<section id="building-blocks-of-a-neural-network">
<h2>Building Blocks of a Neural Network<a class="headerlink" href="#building-blocks-of-a-neural-network" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Neurons (Nodes)</strong>:</p>
<ul class="simple">
<li><p>Each neuron takes one or more inputs, processes them using a mathematical function, and produces an output.</p></li>
<li><p>Example: A neuron can calculate a weighted sum of inputs and apply an activation function to introduce non-linearity.</p></li>
</ul>
</li>
<li><p><strong>Layers</strong>:</p>
<ul class="simple">
<li><p><strong>Input Layer</strong>: Receives raw data (e.g., pixel values of an image).</p></li>
<li><p><strong>Hidden Layers</strong>: Perform intermediate computations to detect patterns and features.</p></li>
<li><p><strong>Output Layer</strong>: Produces the final prediction or classification.</p></li>
</ul>
</li>
<li><p><strong>Weights and Biases</strong>:</p>
<ul class="simple">
<li><p><strong>Weights</strong>: Represent the importance of each input to a neuron.</p></li>
<li><p><strong>Bias</strong>: Helps adjust the output along with the weighted sum, ensuring flexibility.</p></li>
</ul>
</li>
</ol>
</section>
<section id="how-data-flows">
<h2>How Data Flows<a class="headerlink" href="#how-data-flows" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Forward Propagation</strong>:</p>
<ul class="simple">
<li><p>Data flows from the input layer to the output layer through the hidden layers.</p></li>
<li><p>Each neuron processes data using its weights, biases, and activation function.</p></li>
</ul>
</li>
<li><p><strong>Activation Functions</strong>:</p>
<ul class="simple">
<li><p>Add non-linearity to help the network learn complex patterns.</p></li>
<li><p>Common examples: Sigmoid, ReLU, and Tanh.</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># MNIS dataset</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>  <span class="c1"># Normalizacja danych</span>

<span class="c1"># Data Flattening</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>

<span class="c1"># Simple network</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>  <span class="c1"># Warstwa wyjściowa</span>
<span class="p">])</span>

<span class="c1"># Compilation</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> 
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> 
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Training the model</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Errors&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Error (loss)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Wizualizacja dokładności (opcjonalnie)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Accuracy on the training and validation sets&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 6:08 - loss: 2.2959 - accuracy: 0.1562
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/750 [&gt;.............................] - ETA: 0s - loss: 1.1496 - accuracy: 0.7115  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 88/750 [==&gt;...........................] - ETA: 0s - loss: 0.8041 - accuracy: 0.7896
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
132/750 [====&gt;.........................] - ETA: 0s - loss: 0.6680 - accuracy: 0.8250
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
177/750 [======&gt;.......................] - ETA: 0s - loss: 0.5889 - accuracy: 0.8446
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
223/750 [=======&gt;......................] - ETA: 0s - loss: 0.5322 - accuracy: 0.8578
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
268/750 [=========&gt;....................] - ETA: 0s - loss: 0.4918 - accuracy: 0.8676
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
311/750 [===========&gt;..................] - ETA: 0s - loss: 0.4631 - accuracy: 0.8753
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
356/750 [=============&gt;................] - ETA: 0s - loss: 0.4405 - accuracy: 0.8808
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
401/750 [===============&gt;..............] - ETA: 0s - loss: 0.4200 - accuracy: 0.8860
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
444/750 [================&gt;.............] - ETA: 0s - loss: 0.4032 - accuracy: 0.8901
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
487/750 [==================&gt;...........] - ETA: 0s - loss: 0.3876 - accuracy: 0.8942
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
530/750 [====================&gt;.........] - ETA: 0s - loss: 0.3742 - accuracy: 0.8979
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
574/750 [=====================&gt;........] - ETA: 0s - loss: 0.3635 - accuracy: 0.9005
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
617/750 [=======================&gt;......] - ETA: 0s - loss: 0.3521 - accuracy: 0.9031
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
661/750 [=========================&gt;....] - ETA: 0s - loss: 0.3437 - accuracy: 0.9052
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
705/750 [===========================&gt;..] - ETA: 0s - loss: 0.3354 - accuracy: 0.9073
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.9094
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 2s 2ms/step - loss: 0.3271 - accuracy: 0.9094 - val_loss: 0.1803 - val_accuracy: 0.9492
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0822 - accuracy: 0.9844
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 44/750 [&gt;.............................] - ETA: 0s - loss: 0.1599 - accuracy: 0.9553
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 86/750 [==&gt;...........................] - ETA: 0s - loss: 0.1682 - accuracy: 0.9526
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
128/750 [====&gt;.........................] - ETA: 0s - loss: 0.1714 - accuracy: 0.9517
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
171/750 [=====&gt;........................] - ETA: 0s - loss: 0.1738 - accuracy: 0.9510
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
213/750 [=======&gt;......................] - ETA: 0s - loss: 0.1731 - accuracy: 0.9511
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
256/750 [=========&gt;....................] - ETA: 0s - loss: 0.1737 - accuracy: 0.9503
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
298/750 [==========&gt;...................] - ETA: 0s - loss: 0.1688 - accuracy: 0.9514
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
339/750 [============&gt;.................] - ETA: 0s - loss: 0.1655 - accuracy: 0.9529
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
381/750 [==============&gt;...............] - ETA: 0s - loss: 0.1648 - accuracy: 0.9530
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
424/750 [===============&gt;..............] - ETA: 0s - loss: 0.1627 - accuracy: 0.9534
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
466/750 [=================&gt;............] - ETA: 0s - loss: 0.1609 - accuracy: 0.9538
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
507/750 [===================&gt;..........] - ETA: 0s - loss: 0.1586 - accuracy: 0.9541
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
549/750 [====================&gt;.........] - ETA: 0s - loss: 0.1574 - accuracy: 0.9542
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
592/750 [======================&gt;.......] - ETA: 0s - loss: 0.1552 - accuracy: 0.9546
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
634/750 [========================&gt;.....] - ETA: 0s - loss: 0.1533 - accuracy: 0.9552
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
677/750 [==========================&gt;...] - ETA: 0s - loss: 0.1519 - accuracy: 0.9555
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
719/750 [===========================&gt;..] - ETA: 0s - loss: 0.1502 - accuracy: 0.9561
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.1490 - accuracy: 0.9565 - val_loss: 0.1401 - val_accuracy: 0.9603
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 0s - loss: 0.0783 - accuracy: 0.9688
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/750 [&gt;.............................] - ETA: 0s - loss: 0.1097 - accuracy: 0.9737
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/750 [==&gt;...........................] - ETA: 0s - loss: 0.1106 - accuracy: 0.9711
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
123/750 [===&gt;..........................] - ETA: 0s - loss: 0.1116 - accuracy: 0.9700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
164/750 [=====&gt;........................] - ETA: 0s - loss: 0.1138 - accuracy: 0.9683
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
206/750 [=======&gt;......................] - ETA: 0s - loss: 0.1123 - accuracy: 0.9680
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
247/750 [========&gt;.....................] - ETA: 0s - loss: 0.1133 - accuracy: 0.9669
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
288/750 [==========&gt;...................] - ETA: 0s - loss: 0.1129 - accuracy: 0.9671
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/750 [============&gt;.................] - ETA: 0s - loss: 0.1132 - accuracy: 0.9672
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
371/750 [=============&gt;................] - ETA: 0s - loss: 0.1138 - accuracy: 0.9672
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
413/750 [===============&gt;..............] - ETA: 0s - loss: 0.1120 - accuracy: 0.9676
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
456/750 [=================&gt;............] - ETA: 0s - loss: 0.1120 - accuracy: 0.9675
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
499/750 [==================&gt;...........] - ETA: 0s - loss: 0.1105 - accuracy: 0.9678
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
540/750 [====================&gt;.........] - ETA: 0s - loss: 0.1092 - accuracy: 0.9681
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
582/750 [======================&gt;.......] - ETA: 0s - loss: 0.1086 - accuracy: 0.9684
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
625/750 [========================&gt;.....] - ETA: 0s - loss: 0.1078 - accuracy: 0.9685
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
668/750 [=========================&gt;....] - ETA: 0s - loss: 0.1071 - accuracy: 0.9685
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
711/750 [===========================&gt;..] - ETA: 0s - loss: 0.1059 - accuracy: 0.9688
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9693 - val_loss: 0.1129 - val_accuracy: 0.9668
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0361 - accuracy: 0.9844
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/750 [&gt;.............................] - ETA: 0s - loss: 0.0913 - accuracy: 0.9741
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 82/750 [==&gt;...........................] - ETA: 0s - loss: 0.0802 - accuracy: 0.9764
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
123/750 [===&gt;..........................] - ETA: 0s - loss: 0.0789 - accuracy: 0.9775
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
164/750 [=====&gt;........................] - ETA: 0s - loss: 0.0757 - accuracy: 0.9788
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
206/750 [=======&gt;......................] - ETA: 0s - loss: 0.0766 - accuracy: 0.9779
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
245/750 [========&gt;.....................] - ETA: 0s - loss: 0.0776 - accuracy: 0.9773
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
286/750 [==========&gt;...................] - ETA: 0s - loss: 0.0770 - accuracy: 0.9778
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
328/750 [============&gt;.................] - ETA: 0s - loss: 0.0775 - accuracy: 0.9771
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
371/750 [=============&gt;................] - ETA: 0s - loss: 0.0780 - accuracy: 0.9773
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
412/750 [===============&gt;..............] - ETA: 0s - loss: 0.0783 - accuracy: 0.9772
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
452/750 [=================&gt;............] - ETA: 0s - loss: 0.0790 - accuracy: 0.9774
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
492/750 [==================&gt;...........] - ETA: 0s - loss: 0.0789 - accuracy: 0.9772
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
534/750 [====================&gt;.........] - ETA: 0s - loss: 0.0798 - accuracy: 0.9769
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
577/750 [======================&gt;.......] - ETA: 0s - loss: 0.0804 - accuracy: 0.9767
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
619/750 [=======================&gt;......] - ETA: 0s - loss: 0.0800 - accuracy: 0.9766
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
660/750 [=========================&gt;....] - ETA: 0s - loss: 0.0790 - accuracy: 0.9769
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
702/750 [===========================&gt;..] - ETA: 0s - loss: 0.0788 - accuracy: 0.9768
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
743/750 [============================&gt;.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9764
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0795 - accuracy: 0.9765 - val_loss: 0.1041 - val_accuracy: 0.9697
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0437 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/750 [&gt;.............................] - ETA: 0s - loss: 0.0607 - accuracy: 0.9804
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 83/750 [==&gt;...........................] - ETA: 0s - loss: 0.0626 - accuracy: 0.9812
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
123/750 [===&gt;..........................] - ETA: 0s - loss: 0.0612 - accuracy: 0.9817
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
163/750 [=====&gt;........................] - ETA: 0s - loss: 0.0621 - accuracy: 0.9816
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
195/750 [======&gt;.......................] - ETA: 0s - loss: 0.0601 - accuracy: 0.9824
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
234/750 [========&gt;.....................] - ETA: 0s - loss: 0.0621 - accuracy: 0.9817
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
274/750 [=========&gt;....................] - ETA: 0s - loss: 0.0620 - accuracy: 0.9820
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
314/750 [===========&gt;..................] - ETA: 0s - loss: 0.0637 - accuracy: 0.9819
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
354/750 [=============&gt;................] - ETA: 0s - loss: 0.0636 - accuracy: 0.9818
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
391/750 [==============&gt;...............] - ETA: 0s - loss: 0.0639 - accuracy: 0.9817
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
431/750 [================&gt;.............] - ETA: 0s - loss: 0.0624 - accuracy: 0.9820
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
470/750 [=================&gt;............] - ETA: 0s - loss: 0.0624 - accuracy: 0.9819
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
511/750 [===================&gt;..........] - ETA: 0s - loss: 0.0632 - accuracy: 0.9818
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
553/750 [=====================&gt;........] - ETA: 0s - loss: 0.0630 - accuracy: 0.9817
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
595/750 [======================&gt;.......] - ETA: 0s - loss: 0.0629 - accuracy: 0.9819
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
636/750 [========================&gt;.....] - ETA: 0s - loss: 0.0631 - accuracy: 0.9817
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
678/750 [==========================&gt;...] - ETA: 0s - loss: 0.0629 - accuracy: 0.9817
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
719/750 [===========================&gt;..] - ETA: 0s - loss: 0.0632 - accuracy: 0.9817
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0631 - accuracy: 0.9816 - val_loss: 0.0925 - val_accuracy: 0.9718
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0144 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/750 [&gt;.............................] - ETA: 0s - loss: 0.0469 - accuracy: 0.9855
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 84/750 [==&gt;...........................] - ETA: 0s - loss: 0.0474 - accuracy: 0.9855
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
125/750 [====&gt;.........................] - ETA: 0s - loss: 0.0483 - accuracy: 0.9858
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
166/750 [=====&gt;........................] - ETA: 0s - loss: 0.0498 - accuracy: 0.9855
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
207/750 [=======&gt;......................] - ETA: 0s - loss: 0.0497 - accuracy: 0.9857
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
249/750 [========&gt;.....................] - ETA: 0s - loss: 0.0495 - accuracy: 0.9857
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
289/750 [==========&gt;...................] - ETA: 0s - loss: 0.0496 - accuracy: 0.9852
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/750 [============&gt;.................] - ETA: 0s - loss: 0.0498 - accuracy: 0.9852
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
369/750 [=============&gt;................] - ETA: 0s - loss: 0.0508 - accuracy: 0.9847
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
411/750 [===============&gt;..............] - ETA: 0s - loss: 0.0503 - accuracy: 0.9851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
453/750 [=================&gt;............] - ETA: 0s - loss: 0.0494 - accuracy: 0.9853
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
495/750 [==================&gt;...........] - ETA: 0s - loss: 0.0498 - accuracy: 0.9851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
537/750 [====================&gt;.........] - ETA: 0s - loss: 0.0496 - accuracy: 0.9851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
578/750 [======================&gt;.......] - ETA: 0s - loss: 0.0496 - accuracy: 0.9851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
620/750 [=======================&gt;......] - ETA: 0s - loss: 0.0502 - accuracy: 0.9851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
663/750 [=========================&gt;....] - ETA: 0s - loss: 0.0501 - accuracy: 0.9851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
706/750 [===========================&gt;..] - ETA: 0s - loss: 0.0504 - accuracy: 0.9849
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
747/750 [============================&gt;.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9849
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0504 - accuracy: 0.9849 - val_loss: 0.0867 - val_accuracy: 0.9745
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0221 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/750 [&gt;.............................] - ETA: 0s - loss: 0.0348 - accuracy: 0.9916
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 85/750 [==&gt;...........................] - ETA: 0s - loss: 0.0351 - accuracy: 0.9915
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
126/750 [====&gt;.........................] - ETA: 0s - loss: 0.0389 - accuracy: 0.9902
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
168/750 [=====&gt;........................] - ETA: 0s - loss: 0.0370 - accuracy: 0.9907
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
210/750 [=======&gt;......................] - ETA: 0s - loss: 0.0375 - accuracy: 0.9905
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
251/750 [=========&gt;....................] - ETA: 0s - loss: 0.0383 - accuracy: 0.9901
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
292/750 [==========&gt;...................] - ETA: 0s - loss: 0.0388 - accuracy: 0.9900
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
334/750 [============&gt;.................] - ETA: 0s - loss: 0.0393 - accuracy: 0.9897
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
376/750 [==============&gt;...............] - ETA: 0s - loss: 0.0393 - accuracy: 0.9896
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
416/750 [===============&gt;..............] - ETA: 0s - loss: 0.0399 - accuracy: 0.9892
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
459/750 [=================&gt;............] - ETA: 0s - loss: 0.0400 - accuracy: 0.9891
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
501/750 [===================&gt;..........] - ETA: 0s - loss: 0.0401 - accuracy: 0.9890
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
543/750 [====================&gt;.........] - ETA: 0s - loss: 0.0399 - accuracy: 0.9890
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
585/750 [======================&gt;.......] - ETA: 0s - loss: 0.0395 - accuracy: 0.9892
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
627/750 [========================&gt;.....] - ETA: 0s - loss: 0.0396 - accuracy: 0.9891
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
669/750 [=========================&gt;....] - ETA: 0s - loss: 0.0395 - accuracy: 0.9891
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
708/750 [===========================&gt;..] - ETA: 0s - loss: 0.0392 - accuracy: 0.9892
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0391 - accuracy: 0.9891 - val_loss: 0.0910 - val_accuracy: 0.9730
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0251 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/750 [&gt;.............................] - ETA: 0s - loss: 0.0246 - accuracy: 0.9937
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 85/750 [==&gt;...........................] - ETA: 0s - loss: 0.0272 - accuracy: 0.9932
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
126/750 [====&gt;.........................] - ETA: 0s - loss: 0.0280 - accuracy: 0.9924
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
167/750 [=====&gt;........................] - ETA: 0s - loss: 0.0287 - accuracy: 0.9921
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
206/750 [=======&gt;......................] - ETA: 0s - loss: 0.0291 - accuracy: 0.9922
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
247/750 [========&gt;.....................] - ETA: 0s - loss: 0.0294 - accuracy: 0.9922
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
289/750 [==========&gt;...................] - ETA: 0s - loss: 0.0298 - accuracy: 0.9921
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
331/750 [============&gt;.................] - ETA: 0s - loss: 0.0305 - accuracy: 0.9917
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
374/750 [=============&gt;................] - ETA: 0s - loss: 0.0312 - accuracy: 0.9914
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
417/750 [===============&gt;..............] - ETA: 0s - loss: 0.0319 - accuracy: 0.9913
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
459/750 [=================&gt;............] - ETA: 0s - loss: 0.0323 - accuracy: 0.9912
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
501/750 [===================&gt;..........] - ETA: 0s - loss: 0.0321 - accuracy: 0.9912
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
542/750 [====================&gt;.........] - ETA: 0s - loss: 0.0320 - accuracy: 0.9912
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
583/750 [======================&gt;.......] - ETA: 0s - loss: 0.0322 - accuracy: 0.9912
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
625/750 [========================&gt;.....] - ETA: 0s - loss: 0.0321 - accuracy: 0.9911
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
668/750 [=========================&gt;....] - ETA: 0s - loss: 0.0320 - accuracy: 0.9912
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
711/750 [===========================&gt;..] - ETA: 0s - loss: 0.0326 - accuracy: 0.9909
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0328 - accuracy: 0.9909 - val_loss: 0.0869 - val_accuracy: 0.9752
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 0s - loss: 0.0773 - accuracy: 0.9688
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/750 [&gt;.............................] - ETA: 0s - loss: 0.0258 - accuracy: 0.9905
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 83/750 [==&gt;...........................] - ETA: 0s - loss: 0.0263 - accuracy: 0.9921
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
124/750 [===&gt;..........................] - ETA: 0s - loss: 0.0273 - accuracy: 0.9921
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
165/750 [=====&gt;........................] - ETA: 0s - loss: 0.0262 - accuracy: 0.9926
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
206/750 [=======&gt;......................] - ETA: 0s - loss: 0.0257 - accuracy: 0.9930
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
247/750 [========&gt;.....................] - ETA: 0s - loss: 0.0257 - accuracy: 0.9929
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
289/750 [==========&gt;...................] - ETA: 0s - loss: 0.0245 - accuracy: 0.9932
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
330/750 [============&gt;.................] - ETA: 0s - loss: 0.0244 - accuracy: 0.9932
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
371/750 [=============&gt;................] - ETA: 0s - loss: 0.0248 - accuracy: 0.9933
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
413/750 [===============&gt;..............] - ETA: 0s - loss: 0.0248 - accuracy: 0.9933
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
455/750 [=================&gt;............] - ETA: 0s - loss: 0.0250 - accuracy: 0.9930
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
497/750 [==================&gt;...........] - ETA: 0s - loss: 0.0255 - accuracy: 0.9927
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
538/750 [====================&gt;.........] - ETA: 0s - loss: 0.0257 - accuracy: 0.9926
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
578/750 [======================&gt;.......] - ETA: 0s - loss: 0.0254 - accuracy: 0.9927
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
620/750 [=======================&gt;......] - ETA: 0s - loss: 0.0263 - accuracy: 0.9923
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
661/750 [=========================&gt;....] - ETA: 0s - loss: 0.0266 - accuracy: 0.9922
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
703/750 [===========================&gt;..] - ETA: 0s - loss: 0.0270 - accuracy: 0.9920
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
743/750 [============================&gt;.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9920
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 0.0893 - val_accuracy: 0.9758
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0169 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 44/750 [&gt;.............................] - ETA: 0s - loss: 0.0158 - accuracy: 0.9972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 86/750 [==&gt;...........................] - ETA: 0s - loss: 0.0140 - accuracy: 0.9976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
127/750 [====&gt;.........................] - ETA: 0s - loss: 0.0149 - accuracy: 0.9973
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
169/750 [=====&gt;........................] - ETA: 0s - loss: 0.0161 - accuracy: 0.9965
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
210/750 [=======&gt;......................] - ETA: 0s - loss: 0.0180 - accuracy: 0.9957
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
252/750 [=========&gt;....................] - ETA: 0s - loss: 0.0184 - accuracy: 0.9952
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
295/750 [==========&gt;...................] - ETA: 0s - loss: 0.0188 - accuracy: 0.9949
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
337/750 [============&gt;.................] - ETA: 0s - loss: 0.0197 - accuracy: 0.9945
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
379/750 [==============&gt;...............] - ETA: 0s - loss: 0.0193 - accuracy: 0.9946
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
421/750 [===============&gt;..............] - ETA: 0s - loss: 0.0193 - accuracy: 0.9947
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
463/750 [=================&gt;............] - ETA: 0s - loss: 0.0200 - accuracy: 0.9945
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
506/750 [===================&gt;..........] - ETA: 0s - loss: 0.0214 - accuracy: 0.9940
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
548/750 [====================&gt;.........] - ETA: 0s - loss: 0.0218 - accuracy: 0.9938
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
590/750 [======================&gt;.......] - ETA: 0s - loss: 0.0218 - accuracy: 0.9937
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
632/750 [========================&gt;.....] - ETA: 0s - loss: 0.0226 - accuracy: 0.9934
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
673/750 [=========================&gt;....] - ETA: 0s - loss: 0.0226 - accuracy: 0.9935
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
713/750 [===========================&gt;..] - ETA: 0s - loss: 0.0227 - accuracy: 0.9935
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.0876 - val_accuracy: 0.9755
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0184 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 44/750 [&gt;.............................] - ETA: 0s - loss: 0.0130 - accuracy: 0.9975
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 86/750 [==&gt;...........................] - ETA: 0s - loss: 0.0135 - accuracy: 0.9965
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
127/750 [====&gt;.........................] - ETA: 0s - loss: 0.0154 - accuracy: 0.9958
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
167/750 [=====&gt;........................] - ETA: 0s - loss: 0.0161 - accuracy: 0.9962
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
209/750 [=======&gt;......................] - ETA: 0s - loss: 0.0162 - accuracy: 0.9964
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
251/750 [=========&gt;....................] - ETA: 0s - loss: 0.0174 - accuracy: 0.9959
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
292/750 [==========&gt;...................] - ETA: 0s - loss: 0.0174 - accuracy: 0.9956
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
334/750 [============&gt;.................] - ETA: 0s - loss: 0.0172 - accuracy: 0.9958
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
374/750 [=============&gt;................] - ETA: 0s - loss: 0.0175 - accuracy: 0.9957
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
416/750 [===============&gt;..............] - ETA: 0s - loss: 0.0170 - accuracy: 0.9959
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
459/750 [=================&gt;............] - ETA: 0s - loss: 0.0167 - accuracy: 0.9958
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
500/750 [===================&gt;..........] - ETA: 0s - loss: 0.0174 - accuracy: 0.9957
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
542/750 [====================&gt;.........] - ETA: 0s - loss: 0.0176 - accuracy: 0.9955
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
583/750 [======================&gt;.......] - ETA: 0s - loss: 0.0178 - accuracy: 0.9954
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
624/750 [=======================&gt;......] - ETA: 0s - loss: 0.0178 - accuracy: 0.9955
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
666/750 [=========================&gt;....] - ETA: 0s - loss: 0.0181 - accuracy: 0.9953
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
707/750 [===========================&gt;..] - ETA: 0s - loss: 0.0182 - accuracy: 0.9953
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
749/750 [============================&gt;.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9952
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.0901 - val_accuracy: 0.9752
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0111 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/750 [&gt;.............................] - ETA: 0s - loss: 0.0151 - accuracy: 0.9970
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 85/750 [==&gt;...........................] - ETA: 0s - loss: 0.0146 - accuracy: 0.9965
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
129/750 [====&gt;.........................] - ETA: 0s - loss: 0.0139 - accuracy: 0.9975
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
172/750 [=====&gt;........................] - ETA: 0s - loss: 0.0130 - accuracy: 0.9979
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
215/750 [=======&gt;......................] - ETA: 0s - loss: 0.0129 - accuracy: 0.9977
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
258/750 [=========&gt;....................] - ETA: 0s - loss: 0.0127 - accuracy: 0.9976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
300/750 [===========&gt;..................] - ETA: 0s - loss: 0.0124 - accuracy: 0.9978
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
342/750 [============&gt;.................] - ETA: 0s - loss: 0.0124 - accuracy: 0.9977
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
385/750 [==============&gt;...............] - ETA: 0s - loss: 0.0124 - accuracy: 0.9977
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
428/750 [================&gt;.............] - ETA: 0s - loss: 0.0125 - accuracy: 0.9976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
469/750 [=================&gt;............] - ETA: 0s - loss: 0.0126 - accuracy: 0.9975
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
510/750 [===================&gt;..........] - ETA: 0s - loss: 0.0127 - accuracy: 0.9974
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
552/750 [=====================&gt;........] - ETA: 0s - loss: 0.0134 - accuracy: 0.9971
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
594/750 [======================&gt;.......] - ETA: 0s - loss: 0.0140 - accuracy: 0.9969
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
636/750 [========================&gt;.....] - ETA: 0s - loss: 0.0141 - accuracy: 0.9968
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
679/750 [==========================&gt;...] - ETA: 0s - loss: 0.0144 - accuracy: 0.9967
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
722/750 [===========================&gt;..] - ETA: 0s - loss: 0.0148 - accuracy: 0.9966
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.0948 - val_accuracy: 0.9747
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0088 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/750 [&gt;.............................] - ETA: 0s - loss: 0.0114 - accuracy: 0.9967
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 84/750 [==&gt;...........................] - ETA: 0s - loss: 0.0111 - accuracy: 0.9976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
125/750 [====&gt;.........................] - ETA: 0s - loss: 0.0109 - accuracy: 0.9977
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
167/750 [=====&gt;........................] - ETA: 0s - loss: 0.0118 - accuracy: 0.9972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
209/750 [=======&gt;......................] - ETA: 0s - loss: 0.0125 - accuracy: 0.9969
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
251/750 [=========&gt;....................] - ETA: 0s - loss: 0.0126 - accuracy: 0.9969
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
293/750 [==========&gt;...................] - ETA: 0s - loss: 0.0122 - accuracy: 0.9972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
335/750 [============&gt;.................] - ETA: 0s - loss: 0.0121 - accuracy: 0.9972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
377/750 [==============&gt;...............] - ETA: 0s - loss: 0.0123 - accuracy: 0.9971
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
420/750 [===============&gt;..............] - ETA: 0s - loss: 0.0126 - accuracy: 0.9969
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
461/750 [=================&gt;............] - ETA: 0s - loss: 0.0123 - accuracy: 0.9971
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
504/750 [===================&gt;..........] - ETA: 0s - loss: 0.0122 - accuracy: 0.9971
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
546/750 [====================&gt;.........] - ETA: 0s - loss: 0.0126 - accuracy: 0.9969
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
589/750 [======================&gt;.......] - ETA: 0s - loss: 0.0127 - accuracy: 0.9969
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
630/750 [========================&gt;.....] - ETA: 0s - loss: 0.0130 - accuracy: 0.9968
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
673/750 [=========================&gt;....] - ETA: 0s - loss: 0.0128 - accuracy: 0.9968
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
716/750 [===========================&gt;..] - ETA: 0s - loss: 0.0129 - accuracy: 0.9968
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.1009 - val_accuracy: 0.9751
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0071 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/750 [&gt;.............................] - ETA: 0s - loss: 0.0129 - accuracy: 0.9971
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 86/750 [==&gt;...........................] - ETA: 0s - loss: 0.0111 - accuracy: 0.9973
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
129/750 [====&gt;.........................] - ETA: 0s - loss: 0.0098 - accuracy: 0.9979
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
171/750 [=====&gt;........................] - ETA: 0s - loss: 0.0088 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
214/750 [=======&gt;......................] - ETA: 0s - loss: 0.0085 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
255/750 [=========&gt;....................] - ETA: 0s - loss: 0.0084 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
297/750 [==========&gt;...................] - ETA: 0s - loss: 0.0083 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
338/750 [============&gt;.................] - ETA: 0s - loss: 0.0084 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
380/750 [==============&gt;...............] - ETA: 0s - loss: 0.0083 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
422/750 [===============&gt;..............] - ETA: 0s - loss: 0.0091 - accuracy: 0.9983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
464/750 [=================&gt;............] - ETA: 0s - loss: 0.0103 - accuracy: 0.9978
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
506/750 [===================&gt;..........] - ETA: 0s - loss: 0.0103 - accuracy: 0.9977
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
547/750 [====================&gt;.........] - ETA: 0s - loss: 0.0104 - accuracy: 0.9976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
590/750 [======================&gt;.......] - ETA: 0s - loss: 0.0107 - accuracy: 0.9975
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
632/750 [========================&gt;.....] - ETA: 0s - loss: 0.0106 - accuracy: 0.9976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
675/750 [==========================&gt;...] - ETA: 0s - loss: 0.0106 - accuracy: 0.9975
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
717/750 [===========================&gt;..] - ETA: 0s - loss: 0.0106 - accuracy: 0.9976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.0959 - val_accuracy: 0.9747
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0092 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 44/750 [&gt;.............................] - ETA: 0s - loss: 0.0086 - accuracy: 0.9982
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 87/750 [==&gt;...........................] - ETA: 0s - loss: 0.0086 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
129/750 [====&gt;.........................] - ETA: 0s - loss: 0.0080 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
172/750 [=====&gt;........................] - ETA: 0s - loss: 0.0078 - accuracy: 0.9985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
214/750 [=======&gt;......................] - ETA: 0s - loss: 0.0081 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
255/750 [=========&gt;....................] - ETA: 0s - loss: 0.0088 - accuracy: 0.9983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
297/750 [==========&gt;...................] - ETA: 0s - loss: 0.0092 - accuracy: 0.9983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
338/750 [============&gt;.................] - ETA: 0s - loss: 0.0094 - accuracy: 0.9981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
379/750 [==============&gt;...............] - ETA: 0s - loss: 0.0094 - accuracy: 0.9980
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
421/750 [===============&gt;..............] - ETA: 0s - loss: 0.0092 - accuracy: 0.9981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
463/750 [=================&gt;............] - ETA: 0s - loss: 0.0089 - accuracy: 0.9981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
505/750 [===================&gt;..........] - ETA: 0s - loss: 0.0090 - accuracy: 0.9981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
548/750 [====================&gt;.........] - ETA: 0s - loss: 0.0089 - accuracy: 0.9981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
590/750 [======================&gt;.......] - ETA: 0s - loss: 0.0089 - accuracy: 0.9982
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
631/750 [========================&gt;.....] - ETA: 0s - loss: 0.0091 - accuracy: 0.9981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
673/750 [=========================&gt;....] - ETA: 0s - loss: 0.0094 - accuracy: 0.9980
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
716/750 [===========================&gt;..] - ETA: 0s - loss: 0.0094 - accuracy: 0.9980
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0921 - val_accuracy: 0.9777
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0044 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/750 [&gt;.............................] - ETA: 0s - loss: 0.0054 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 85/750 [==&gt;...........................] - ETA: 0s - loss: 0.0053 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
126/750 [====&gt;.........................] - ETA: 0s - loss: 0.0062 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
168/750 [=====&gt;........................] - ETA: 0s - loss: 0.0060 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
210/750 [=======&gt;......................] - ETA: 0s - loss: 0.0057 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
252/750 [=========&gt;....................] - ETA: 0s - loss: 0.0053 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
294/750 [==========&gt;...................] - ETA: 0s - loss: 0.0053 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
335/750 [============&gt;.................] - ETA: 0s - loss: 0.0055 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
376/750 [==============&gt;...............] - ETA: 0s - loss: 0.0055 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
417/750 [===============&gt;..............] - ETA: 0s - loss: 0.0056 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
458/750 [=================&gt;............] - ETA: 0s - loss: 0.0055 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
498/750 [==================&gt;...........] - ETA: 0s - loss: 0.0054 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
540/750 [====================&gt;.........] - ETA: 0s - loss: 0.0055 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
581/750 [======================&gt;.......] - ETA: 0s - loss: 0.0059 - accuracy: 0.9992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
622/750 [=======================&gt;......] - ETA: 0s - loss: 0.0061 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
663/750 [=========================&gt;....] - ETA: 0s - loss: 0.0063 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
704/750 [===========================&gt;..] - ETA: 0s - loss: 0.0066 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
746/750 [============================&gt;.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.1029 - val_accuracy: 0.9755
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0113 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/750 [&gt;.............................] - ETA: 0s - loss: 0.0091 - accuracy: 0.9963
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 84/750 [==&gt;...........................] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
127/750 [====&gt;.........................] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
169/750 [=====&gt;........................] - ETA: 0s - loss: 0.0067 - accuracy: 0.9983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
213/750 [=======&gt;......................] - ETA: 0s - loss: 0.0064 - accuracy: 0.9985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
256/750 [=========&gt;....................] - ETA: 0s - loss: 0.0060 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
297/750 [==========&gt;...................] - ETA: 0s - loss: 0.0067 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
339/750 [============&gt;.................] - ETA: 0s - loss: 0.0066 - accuracy: 0.9985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
381/750 [==============&gt;...............] - ETA: 0s - loss: 0.0068 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
424/750 [===============&gt;..............] - ETA: 0s - loss: 0.0070 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
467/750 [=================&gt;............] - ETA: 0s - loss: 0.0069 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
509/750 [===================&gt;..........] - ETA: 0s - loss: 0.0066 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
549/750 [====================&gt;.........] - ETA: 0s - loss: 0.0065 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
587/750 [======================&gt;.......] - ETA: 0s - loss: 0.0066 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
629/750 [========================&gt;.....] - ETA: 0s - loss: 0.0068 - accuracy: 0.9985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
671/750 [=========================&gt;....] - ETA: 0s - loss: 0.0070 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
712/750 [===========================&gt;..] - ETA: 0s - loss: 0.0071 - accuracy: 0.9983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1043 - val_accuracy: 0.9753
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 18/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0016 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/750 [&gt;.............................] - ETA: 0s - loss: 0.0081 - accuracy: 0.9985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 84/750 [==&gt;...........................] - ETA: 0s - loss: 0.0096 - accuracy: 0.9978
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
125/750 [====&gt;.........................] - ETA: 0s - loss: 0.0080 - accuracy: 0.9981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
168/750 [=====&gt;........................] - ETA: 0s - loss: 0.0071 - accuracy: 0.9982
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
210/750 [=======&gt;......................] - ETA: 0s - loss: 0.0065 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
250/750 [=========&gt;....................] - ETA: 0s - loss: 0.0062 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
291/750 [==========&gt;...................] - ETA: 0s - loss: 0.0058 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
332/750 [============&gt;.................] - ETA: 0s - loss: 0.0055 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
374/750 [=============&gt;................] - ETA: 0s - loss: 0.0058 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
417/750 [===============&gt;..............] - ETA: 0s - loss: 0.0059 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
459/750 [=================&gt;............] - ETA: 0s - loss: 0.0061 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
501/750 [===================&gt;..........] - ETA: 0s - loss: 0.0059 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
543/750 [====================&gt;.........] - ETA: 0s - loss: 0.0059 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
585/750 [======================&gt;.......] - ETA: 0s - loss: 0.0059 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
626/750 [========================&gt;.....] - ETA: 0s - loss: 0.0059 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
667/750 [=========================&gt;....] - ETA: 0s - loss: 0.0059 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
708/750 [===========================&gt;..] - ETA: 0s - loss: 0.0058 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.1022 - val_accuracy: 0.9769
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 19/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0016 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/750 [&gt;.............................] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/750 [==&gt;...........................] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
122/750 [===&gt;..........................] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
164/750 [=====&gt;........................] - ETA: 0s - loss: 0.0047 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
205/750 [=======&gt;......................] - ETA: 0s - loss: 0.0050 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
245/750 [========&gt;.....................] - ETA: 0s - loss: 0.0048 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
287/750 [==========&gt;...................] - ETA: 0s - loss: 0.0051 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/750 [============&gt;.................] - ETA: 0s - loss: 0.0054 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
369/750 [=============&gt;................] - ETA: 0s - loss: 0.0053 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
408/750 [===============&gt;..............] - ETA: 0s - loss: 0.0053 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
449/750 [================&gt;.............] - ETA: 0s - loss: 0.0053 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
491/750 [==================&gt;...........] - ETA: 0s - loss: 0.0054 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
533/750 [====================&gt;.........] - ETA: 0s - loss: 0.0056 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
573/750 [=====================&gt;........] - ETA: 0s - loss: 0.0057 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
613/750 [=======================&gt;......] - ETA: 0s - loss: 0.0057 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
655/750 [=========================&gt;....] - ETA: 0s - loss: 0.0056 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
695/750 [==========================&gt;...] - ETA: 0s - loss: 0.0056 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
737/750 [============================&gt;.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.1046 - val_accuracy: 0.9768
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 20/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0022 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 40/750 [&gt;.............................] - ETA: 0s - loss: 0.0062 - accuracy: 0.9977
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 79/750 [==&gt;...........................] - ETA: 0s - loss: 0.0043 - accuracy: 0.9988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
119/750 [===&gt;..........................] - ETA: 0s - loss: 0.0042 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
159/750 [=====&gt;........................] - ETA: 0s - loss: 0.0038 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
198/750 [======&gt;.......................] - ETA: 0s - loss: 0.0037 - accuracy: 0.9992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
237/750 [========&gt;.....................] - ETA: 0s - loss: 0.0038 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
277/750 [==========&gt;...................] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
318/750 [===========&gt;..................] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
358/750 [=============&gt;................] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
399/750 [==============&gt;...............] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
437/750 [================&gt;.............] - ETA: 0s - loss: 0.0034 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
471/750 [=================&gt;............] - ETA: 0s - loss: 0.0034 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
501/750 [===================&gt;..........] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
536/750 [====================&gt;.........] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
572/750 [=====================&gt;........] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
613/750 [=======================&gt;......] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
654/750 [=========================&gt;....] - ETA: 0s - loss: 0.0037 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
696/750 [==========================&gt;...] - ETA: 0s - loss: 0.0045 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
738/750 [============================&gt;.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.1077 - val_accuracy: 0.9758
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 21/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 8.6494e-04 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/750 [&gt;.............................] - ETA: 0s - loss: 0.0049 - accuracy: 0.9989    
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 83/750 [==&gt;...........................] - ETA: 0s - loss: 0.0070 - accuracy: 0.9979
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
125/750 [====&gt;.........................] - ETA: 0s - loss: 0.0082 - accuracy: 0.9980
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
166/750 [=====&gt;........................] - ETA: 0s - loss: 0.0073 - accuracy: 0.9983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
207/750 [=======&gt;......................] - ETA: 0s - loss: 0.0069 - accuracy: 0.9983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
247/750 [========&gt;.....................] - ETA: 0s - loss: 0.0066 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
288/750 [==========&gt;...................] - ETA: 0s - loss: 0.0061 - accuracy: 0.9985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/750 [============&gt;.................] - ETA: 0s - loss: 0.0061 - accuracy: 0.9985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
371/750 [=============&gt;................] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
412/750 [===============&gt;..............] - ETA: 0s - loss: 0.0058 - accuracy: 0.9986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
453/750 [=================&gt;............] - ETA: 0s - loss: 0.0056 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
494/750 [==================&gt;...........] - ETA: 0s - loss: 0.0055 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
533/750 [====================&gt;.........] - ETA: 0s - loss: 0.0053 - accuracy: 0.9988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
574/750 [=====================&gt;........] - ETA: 0s - loss: 0.0051 - accuracy: 0.9988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
615/750 [=======================&gt;......] - ETA: 0s - loss: 0.0051 - accuracy: 0.9988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
655/750 [=========================&gt;....] - ETA: 0s - loss: 0.0051 - accuracy: 0.9988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
696/750 [==========================&gt;...] - ETA: 0s - loss: 0.0051 - accuracy: 0.9988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
737/750 [============================&gt;.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1048 - val_accuracy: 0.9755
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 22/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 1.8849e-04 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/750 [&gt;.............................] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993    
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 86/750 [==&gt;...........................] - ETA: 0s - loss: 0.0028 - accuracy: 0.9996
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
127/750 [====&gt;.........................] - ETA: 0s - loss: 0.0029 - accuracy: 0.9996
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
170/750 [=====&gt;........................] - ETA: 0s - loss: 0.0030 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
211/750 [=======&gt;......................] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
251/750 [=========&gt;....................] - ETA: 0s - loss: 0.0028 - accuracy: 0.9996
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
291/750 [==========&gt;...................] - ETA: 0s - loss: 0.0028 - accuracy: 0.9996
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
333/750 [============&gt;.................] - ETA: 0s - loss: 0.0027 - accuracy: 0.9996
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
375/750 [==============&gt;...............] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
417/750 [===============&gt;..............] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
459/750 [=================&gt;............] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
501/750 [===================&gt;..........] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
543/750 [====================&gt;.........] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
586/750 [======================&gt;.......] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
629/750 [========================&gt;.....] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
671/750 [=========================&gt;....] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
711/750 [===========================&gt;..] - ETA: 0s - loss: 0.0036 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1092 - val_accuracy: 0.9779
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 23/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0039 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 44/750 [&gt;.............................] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 88/750 [==&gt;...........................] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
131/750 [====&gt;.........................] - ETA: 0s - loss: 0.0033 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
175/750 [======&gt;.......................] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
217/750 [=======&gt;......................] - ETA: 0s - loss: 0.0032 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
259/750 [=========&gt;....................] - ETA: 0s - loss: 0.0032 - accuracy: 0.9994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
302/750 [===========&gt;..................] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
345/750 [============&gt;.................] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
388/750 [==============&gt;...............] - ETA: 0s - loss: 0.0033 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
429/750 [================&gt;.............] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
472/750 [=================&gt;............] - ETA: 0s - loss: 0.0033 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
515/750 [===================&gt;..........] - ETA: 0s - loss: 0.0037 - accuracy: 0.9992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
557/750 [=====================&gt;........] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
599/750 [======================&gt;.......] - ETA: 0s - loss: 0.0039 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
642/750 [========================&gt;.....] - ETA: 0s - loss: 0.0041 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
685/750 [==========================&gt;...] - ETA: 0s - loss: 0.0042 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
724/750 [===========================&gt;..] - ETA: 0s - loss: 0.0047 - accuracy: 0.9988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1203 - val_accuracy: 0.9740
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 24/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0115 - accuracy: 1.0000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/750 [&gt;.............................] - ETA: 0s - loss: 0.0071 - accuracy: 0.9970
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/750 [==&gt;...........................] - ETA: 0s - loss: 0.0057 - accuracy: 0.9983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
121/750 [===&gt;..........................] - ETA: 0s - loss: 0.0052 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
162/750 [=====&gt;........................] - ETA: 0s - loss: 0.0053 - accuracy: 0.9984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/750 [=======&gt;......................] - ETA: 0s - loss: 0.0046 - accuracy: 0.9987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
246/750 [========&gt;.....................] - ETA: 0s - loss: 0.0042 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
288/750 [==========&gt;...................] - ETA: 0s - loss: 0.0042 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/750 [============&gt;.................] - ETA: 0s - loss: 0.0042 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
371/750 [=============&gt;................] - ETA: 0s - loss: 0.0040 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
413/750 [===============&gt;..............] - ETA: 0s - loss: 0.0043 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
455/750 [=================&gt;............] - ETA: 0s - loss: 0.0046 - accuracy: 0.9988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
497/750 [==================&gt;...........] - ETA: 0s - loss: 0.0046 - accuracy: 0.9988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
539/750 [====================&gt;.........] - ETA: 0s - loss: 0.0044 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
582/750 [======================&gt;.......] - ETA: 0s - loss: 0.0044 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
624/750 [=======================&gt;......] - ETA: 0s - loss: 0.0043 - accuracy: 0.9990
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
666/750 [=========================&gt;....] - ETA: 0s - loss: 0.0043 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
708/750 [===========================&gt;..] - ETA: 0s - loss: 0.0043 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
750/750 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.1241 - val_accuracy: 0.9752
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 25/100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/750 [..............................] - ETA: 1s - loss: 0.0299 - accuracy: 0.9844
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/750 [&gt;.............................] - ETA: 0s - loss: 0.0044 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 86/750 [==&gt;...........................] - ETA: 0s - loss: 0.0044 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
129/750 [====&gt;.........................] - ETA: 0s - loss: 0.0037 - accuracy: 0.9992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
172/750 [=====&gt;........................] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
215/750 [=======&gt;......................] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
258/750 [=========&gt;....................] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
300/750 [===========&gt;..................] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
341/750 [============&gt;.................] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
383/750 [==============&gt;...............] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
425/750 [================&gt;.............] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="nn">Input In [2],</span> in <span class="ni">&lt;cell line: 28&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span> <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> 
<span class="g g-Whitespace">     </span><span class="mi">24</span>               <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> 
<span class="g g-Whitespace">     </span><span class="mi">25</span>               <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span> <span class="c1"># Training the model</span>
<span class="ne">---&gt; </span><span class="mi">28</span> <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">30</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">31</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training error&#39;</span><span class="p">)</span>

<span class="nn">File ~\AppData\Roaming\Python\Python39\site-packages\keras\utils\traceback_utils.py:65,</span> in <span class="ni">filter_traceback.&lt;locals&gt;.error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span> <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">     </span><span class="mi">64</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">65</span>     <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">66</span> <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">67</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">File ~\AppData\Roaming\Python\Python39\site-packages\keras\engine\training.py:1650,</span> in <span class="ni">Model.fit</span><span class="nt">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="g g-Whitespace">   </span><span class="mi">1642</span> <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1643</span>     <span class="s2">&quot;train&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1644</span>     <span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1647</span>     <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1648</span> <span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1649</span>     <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1650</span>     <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1651</span>     <span class="k">if</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1652</span>         <span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="nn">File ~\AppData\Roaming\Python\Python39\site-packages\tensorflow\python\util\traceback_utils.py:150,</span> in <span class="ni">filter_traceback.&lt;locals&gt;.error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">148</span> <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">149</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">150</span>   <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">151</span> <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">152</span>   <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">File ~\AppData\Roaming\Python\Python39\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py:880,</span> in <span class="ni">Function.__call__</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">877</span> <span class="n">compiler</span> <span class="o">=</span> <span class="s2">&quot;xla&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span> <span class="k">else</span> <span class="s2">&quot;nonXla&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">879</span> <span class="k">with</span> <span class="n">OptionalXlaContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">880</span>   <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">882</span> <span class="n">new_tracing_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experimental_get_tracing_count</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">883</span> <span class="n">without_tracing</span> <span class="o">=</span> <span class="p">(</span><span class="n">tracing_count</span> <span class="o">==</span> <span class="n">new_tracing_count</span><span class="p">)</span>

<span class="nn">File ~\AppData\Roaming\Python\Python39\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py:912,</span> in <span class="ni">Function._call</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">909</span>   <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">910</span>   <span class="c1"># In this case we have created variables on the first call, so we run the</span>
<span class="g g-Whitespace">    </span><span class="mi">911</span>   <span class="c1"># defunned version which is guaranteed to never create variables.</span>
<span class="ne">--&gt; </span><span class="mi">912</span>   <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_no_variable_creation_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>
<span class="g g-Whitespace">    </span><span class="mi">913</span> <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variable_creation_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">914</span>   <span class="c1"># Release the lock early so that multiple threads can perform the call</span>
<span class="g g-Whitespace">    </span><span class="mi">915</span>   <span class="c1"># in parallel.</span>
<span class="g g-Whitespace">    </span><span class="mi">916</span>   <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>

<span class="nn">File ~\AppData\Roaming\Python\Python39\site-packages\tensorflow\python\eager\polymorphic_function\tracing_compiler.py:134,</span> in <span class="ni">TracingCompiler.__call__</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">131</span> <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">132</span>   <span class="p">(</span><span class="n">concrete_function</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">133</span>    <span class="n">filtered_flat_args</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_define_function</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">134</span> <span class="k">return</span> <span class="n">concrete_function</span><span class="o">.</span><span class="n">_call_flat</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">135</span>     <span class="n">filtered_flat_args</span><span class="p">,</span> <span class="n">captured_inputs</span><span class="o">=</span><span class="n">concrete_function</span><span class="o">.</span><span class="n">captured_inputs</span><span class="p">)</span>

<span class="nn">File ~\AppData\Roaming\Python\Python39\site-packages\tensorflow\python\eager\polymorphic_function\monomorphic_function.py:1745,</span> in <span class="ni">ConcreteFunction._call_flat</span><span class="nt">(self, args, captured_inputs, cancellation_manager)</span>
<span class="g g-Whitespace">   </span><span class="mi">1741</span> <span class="n">possible_gradient_type</span> <span class="o">=</span> <span class="n">gradients_util</span><span class="o">.</span><span class="n">PossibleTapeGradientTypes</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1742</span> <span class="k">if</span> <span class="p">(</span><span class="n">possible_gradient_type</span> <span class="o">==</span> <span class="n">gradients_util</span><span class="o">.</span><span class="n">POSSIBLE_GRADIENT_TYPES_NONE</span>
<span class="g g-Whitespace">   </span><span class="mi">1743</span>     <span class="ow">and</span> <span class="n">executing_eagerly</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1744</span>   <span class="c1"># No tape is watching; skip to running the function.</span>
<span class="ne">-&gt; </span><span class="mi">1745</span>   <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_call_outputs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_inference_function</span><span class="o">.</span><span class="n">call</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1746</span>       <span class="n">ctx</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">cancellation_manager</span><span class="o">=</span><span class="n">cancellation_manager</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1747</span> <span class="n">forward_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_forward_and_backward_functions</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1748</span>     <span class="n">args</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1749</span>     <span class="n">possible_gradient_type</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1750</span>     <span class="n">executing_eagerly</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1751</span> <span class="n">forward_function</span><span class="p">,</span> <span class="n">args_with_tangents</span> <span class="o">=</span> <span class="n">forward_backward</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>

<span class="nn">File ~\AppData\Roaming\Python\Python39\site-packages\tensorflow\python\eager\polymorphic_function\monomorphic_function.py:378,</span> in <span class="ni">_EagerDefinedFunction.call</span><span class="nt">(self, ctx, args, cancellation_manager)</span>
<span class="g g-Whitespace">    </span><span class="mi">376</span> <span class="k">with</span> <span class="n">_InterpolateFunctionError</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">377</span>   <span class="k">if</span> <span class="n">cancellation_manager</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">378</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">379</span>         <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">380</span>         <span class="n">num_outputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">381</span>         <span class="n">inputs</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">382</span>         <span class="n">attrs</span><span class="o">=</span><span class="n">attrs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">383</span>         <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">384</span>   <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">385</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute_with_cancellation</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">386</span>         <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">387</span>         <span class="n">num_outputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">390</span>         <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">391</span>         <span class="n">cancellation_manager</span><span class="o">=</span><span class="n">cancellation_manager</span><span class="p">)</span>

<span class="nn">File ~\AppData\Roaming\Python\Python39\site-packages\tensorflow\python\eager\execute.py:52,</span> in <span class="ni">quick_execute</span><span class="nt">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="g g-Whitespace">     </span><span class="mi">50</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span>   <span class="n">ctx</span><span class="o">.</span><span class="n">ensure_initialized</span><span class="p">()</span>
<span class="ne">---&gt; </span><span class="mi">52</span>   <span class="n">tensors</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_Execute</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">_handle</span><span class="p">,</span> <span class="n">device_name</span><span class="p">,</span> <span class="n">op_name</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">53</span>                                       <span class="n">inputs</span><span class="p">,</span> <span class="n">attrs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span> <span class="k">except</span> <span class="n">core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">55</span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="how-neural-network-architecture-impacts-predictions">
<h2>How Neural Network Architecture Impacts Predictions<a class="headerlink" href="#how-neural-network-architecture-impacts-predictions" title="Permalink to this heading">#</a></h2>
<section id="number-of-layers">
<h3>1. <strong>Number of Layers</strong><a class="headerlink" href="#number-of-layers" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Shallow Networks</strong>:</p>
<ul>
<li><p>Work well for problems with simple patterns and relationships.</p></li>
<li><p>Examples: Predicting linear trends or simple classifications.</p></li>
</ul>
</li>
<li><p><strong>Deep Networks</strong>:</p>
<ul>
<li><p>Better suited for complex problems with intricate relationships (e.g., image recognition, speech synthesis).</p></li>
<li><p>More layers allow the network to extract and combine high-level features from data.</p></li>
</ul>
</li>
</ul>
</section>
<section id="number-of-neurons-in-each-layer">
<h3>2. <strong>Number of Neurons in Each Layer</strong><a class="headerlink" href="#number-of-neurons-in-each-layer" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Too Few Neurons</strong>:</p>
<ul>
<li><p>Can lead to underfitting, where the network cannot capture the complexity of the data.</p></li>
<li><p>Example: A network with insufficient neurons might fail to recognize subtle patterns in images.</p></li>
</ul>
</li>
<li><p><strong>Too Many Neurons</strong>:</p>
<ul>
<li><p>Can lead to overfitting, where the network memorizes the training data rather than generalizing to new data.</p></li>
<li><p>Example: A network may perform perfectly on training data but fail on unseen examples.</p></li>
</ul>
</li>
</ul>
</section>
<section id="choice-of-activation-functions">
<h3>3. <strong>Choice of Activation Functions</strong><a class="headerlink" href="#choice-of-activation-functions" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Activation functions determine how the data flows and transforms through the network.</p>
<ul>
<li><p>Example: ReLU is effective for deep networks because it mitigates the vanishing gradient problem, enabling better training of deep layers.</p></li>
</ul>
</li>
<li><p>The choice of activation function impacts the ability of the network to model complex, non-linear patterns.</p></li>
</ul>
</section>
<section id="regularization-techniques">
<h3>4. <strong>Regularization Techniques</strong><a class="headerlink" href="#regularization-techniques" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Regularization (e.g., dropout, L2 regularization) prevents overfitting and ensures the network generalizes well to unseen data.</p>
<ul>
<li><p>Example: Dropout randomly disables a fraction of neurons during training, forcing the network to learn robust features.</p></li>
</ul>
</li>
</ul>
</section>
<section id="depth-vs-breadth">
<h3>5. <strong>Depth vs. Breadth</strong><a class="headerlink" href="#depth-vs-breadth" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Deeper Networks</strong>:</p>
<ul>
<li><p>Learn hierarchical patterns (e.g., edges → shapes → objects in images).</p></li>
</ul>
</li>
<li><p><strong>Wider Networks</strong>:</p>
<ul>
<li><p>Capture more features at the same level but may fail to model hierarchical relationships.</p></li>
</ul>
</li>
</ul>
</section>
<section id="connectivity-and-architecture">
<h3>6. <strong>Connectivity and Architecture</strong><a class="headerlink" href="#connectivity-and-architecture" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Specialized architectures like Convolutional Neural Networks (CNNs) for images or Recurrent Neural Networks (RNNs) for sequential data influence predictions by tailoring the network to specific data structures.</p>
<ul>
<li><p>Example: CNNs are excellent at identifying spatial patterns in images.</p></li>
</ul>
</li>
</ul>
</section>
<section id="summary">
<h3><strong>Summary</strong><a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h3>
<p>The architecture of a neural network significantly impacts its ability to make accurate predictions. Factors like the number of layers, neurons</p>
<p>See for examples: <a class="reference external" href="https://alexlenail.me/NN-SVG/">https://alexlenail.me/NN-SVG/</a></p>
<p>See for some examples: <a class="reference external" href="https://playground.tensorflow.org">https://playground.tensorflow.org</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="c1"># Loading and preparing the MNIST dataset</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Normalizing the data</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="c1"># Splitting the data into training and validation sets</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Reshaping input data</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">x_val</span> <span class="o">=</span> <span class="n">x_val</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>

<span class="c1"># Parameters to test</span>
<span class="n">layer_configs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>  <span class="c1"># Number of layers</span>
<span class="n">neurons_configs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>  <span class="c1"># Number of neurons per layer</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Testing different configurations</span>
<span class="k">for</span> <span class="n">num_layers</span> <span class="ow">in</span> <span class="n">layer_configs</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">num_neurons</span> <span class="ow">in</span> <span class="n">neurons_configs</span><span class="p">:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="c1"># Building the model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_neurons</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,)))</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_neurons</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>  <span class="c1"># Output layer</span>
        
        <span class="c1"># Compiling the model</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> 
                      <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> 
                      <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
        
        <span class="c1"># Training the model</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
                            <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> 
                            <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Evaluating the model</span>
        <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">num_neurons</span><span class="p">,</span> <span class="n">val_accuracy</span><span class="p">))</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of layers: </span><span class="si">{</span><span class="n">num_layers</span><span class="si">}</span><span class="s2">, Number of neurons: </span><span class="si">{</span><span class="n">num_neurons</span><span class="si">}</span><span class="s2">, Validation accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Time: </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
        

<span class="c1"># Visualizing the results</span>
<span class="n">results_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="k">for</span> <span class="n">num_layers</span> <span class="ow">in</span> <span class="n">layer_configs</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neurons_configs</span><span class="p">,</span> <span class="n">results_array</span><span class="p">[</span><span class="n">results_array</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_layers</span><span class="p">][:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">num_layers</span><span class="si">}</span><span class="s1"> layers&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Impact of the number of neurons and layers on validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of neurons per layer&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of layers: 1, Number of neurons: 32, Validation accuracy: 0.9560, Time: 6.54s
Number of layers: 1, Number of neurons: 64, Validation accuracy: 0.9648, Time: 6.97s
Number of layers: 1, Number of neurons: 128, Validation accuracy: 0.9737, Time: 9.05s
Number of layers: 2, Number of neurons: 32, Validation accuracy: 0.9603, Time: 6.88s
Number of layers: 2, Number of neurons: 64, Validation accuracy: 0.9633, Time: 7.44s
Number of layers: 2, Number of neurons: 128, Validation accuracy: 0.9773, Time: 9.38s
Number of layers: 3, Number of neurons: 32, Validation accuracy: 0.9607, Time: 8.57s
Number of layers: 3, Number of neurons: 64, Validation accuracy: 0.9705, Time: 9.37s
Number of layers: 3, Number of neurons: 128, Validation accuracy: 0.9737, Time: 11.29s
</pre></div>
</div>
<img alt="../_images/4c46b3c1a274091bc9759b1fcfae658bf602b66d1a9790476967b7c8b2f36d8e.png" src="../_images/4c46b3c1a274091bc9759b1fcfae658bf602b66d1a9790476967b7c8b2f36d8e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">SimpleRNN</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Reshape</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="c1"># Loading and preparing MNIST data</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="c1"># Adding channel dimension for CNN</span>
<span class="n">x_train_cnn</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">x_test_cnn</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="c1"># Preparing data for RNN</span>
<span class="n">x_train_rnn</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">x_test_rnn</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="c1"># Function to train and evaluate a model</span>
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> 
                  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> 
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">test_accuracy</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="c1"># Fully Connected Network (FC)</span>
<span class="n">fc_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="n">fc_accuracy</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">fc_model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy (FC): </span><span class="si">{</span><span class="n">fc_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Time: </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="c1"># Convolutional Neural Network (CNN)</span>
<span class="n">cnn_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="n">cnn_accuracy</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">cnn_model</span><span class="p">,</span> <span class="n">x_train_cnn</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_cnn</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy (CNN): </span><span class="si">{</span><span class="n">cnn_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Time: </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="c1"># Recurrent Neural Network (RNN)</span>
<span class="n">rnn_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="n">rnn_accuracy</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">rnn_model</span><span class="p">,</span> <span class="n">x_train_rnn</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_rnn</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy (RNN): </span><span class="si">{</span><span class="n">rnn_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Time: </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="c1"># LSTM Network</span>
<span class="n">lstm_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">lstm_accuracy</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">lstm_model</span><span class="p">,</span> <span class="n">x_train_rnn</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_rnn</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy (LSTM): </span><span class="si">{</span><span class="n">lstm_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Time: </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>

<span class="c1"># Comparing results</span>
<span class="n">types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;FC&#39;</span><span class="p">,</span> <span class="s1">&#39;CNN&#39;</span><span class="p">,</span> <span class="s1">&#39;RNN&#39;</span><span class="p">,</span> <span class="s1">&#39;LSTM&#39;</span><span class="p">]</span>
<span class="n">accuracies</span> <span class="o">=</span> <span class="p">[</span><span class="n">fc_accuracy</span><span class="p">,</span> <span class="n">cnn_accuracy</span><span class="p">,</span> <span class="n">rnn_accuracy</span><span class="p">,</span> <span class="n">lstm_accuracy</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">types</span><span class="p">,</span> <span class="n">accuracies</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Comparison of accuracy for different network types on MNIST&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy (FC): 0.9772, Time: 0.04 s
Accuracy (CNN): 0.9877, Time: 0.08 s
Accuracy (RNN): 0.9568, Time: 0.14 s
Accuracy (LSTM): 0.9817, Time: 118.47 s
</pre></div>
</div>
<img alt="../_images/ad877a8cb5120804bcc64aa3f66dc50688f934ea4f9a96aaaa249dbe90cd6856.png" src="../_images/ad877a8cb5120804bcc64aa3f66dc50688f934ea4f9a96aaaa249dbe90cd6856.png" />
</div>
</div>
</section>
</section>
<section id="common-activation-functions">
<h2>Common Activation Functions<a class="headerlink" href="#common-activation-functions" title="Permalink to this heading">#</a></h2>
<p>Activation functions are a crucial component of neural networks, as they introduce non-linearity, enabling the network to model complex relationships in the data.</p>
<section id="sigmoid-function">
<h3>1. <strong>Sigmoid Function</strong><a class="headerlink" href="#sigmoid-function" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\( f(x) = \frac{1}{1 + e^{-x}} \)</span></p></li>
<li><p><strong>Output Range</strong>: (0, 1)</p></li>
<li><p><strong>Use Case</strong>:</p>
<ul>
<li><p>Commonly used in the output layer for binary classification problems.</p></li>
</ul>
</li>
<li><p><strong>Pros</strong>:</p>
<ul>
<li><p>Smooth gradient, useful for probability-based outputs.</p></li>
</ul>
</li>
<li><p><strong>Cons</strong>:</p>
<ul>
<li><p>Prone to the vanishing gradient problem in deep networks.</p></li>
</ul>
</li>
</ul>
</section>
<section id="relu-rectified-linear-unit">
<h3>2. <strong>ReLU (Rectified Linear Unit)</strong><a class="headerlink" href="#relu-rectified-linear-unit" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\( f(x) = \max(0, x) \)</span></p></li>
<li><p><strong>Output Range</strong>: [0, <span class="math notranslate nohighlight">\( \infty \)</span>)</p></li>
<li><p><strong>Use Case</strong>:</p>
<ul>
<li><p>Widely used in hidden layers of deep networks.</p></li>
</ul>
</li>
<li><p><strong>Pros</strong>:</p>
<ul>
<li><p>Efficient computation and mitigates the vanishing gradient problem.</p></li>
</ul>
</li>
<li><p><strong>Cons</strong>:</p>
<ul>
<li><p>Can cause dead neurons (outputs stuck at 0) if weights are poorly initialized.</p></li>
</ul>
</li>
</ul>
</section>
<section id="tanh-hyperbolic-tangent">
<h3>3. <strong>Tanh (Hyperbolic Tangent)</strong><a class="headerlink" href="#tanh-hyperbolic-tangent" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\( f(x) = \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \)</span></p></li>
<li><p><strong>Output Range</strong>: (-1, 1)</p></li>
<li><p><strong>Use Case</strong>:</p>
<ul>
<li><p>Used in cases where negative values are meaningful.</p></li>
</ul>
</li>
<li><p><strong>Pros</strong>:</p>
<ul>
<li><p>Zero-centered output, making optimization easier than sigmoid.</p></li>
</ul>
</li>
<li><p><strong>Cons</strong>:</p>
<ul>
<li><p>Still prone to the vanishing gradient problem.</p></li>
</ul>
</li>
</ul>
</section>
<section id="softmax-function">
<h3>4. <strong>Softmax Function</strong><a class="headerlink" href="#softmax-function" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\( f(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}} \)</span> for <span class="math notranslate nohighlight">\( i = 1, 2, \dots, n \)</span></p></li>
<li><p><strong>Output Range</strong>: (0, 1), with the sum of outputs equal to 1.</p></li>
<li><p><strong>Use Case</strong>:</p>
<ul>
<li><p>Used in the output layer for multi-class classification problems.</p></li>
</ul>
</li>
<li><p><strong>Pros</strong>:</p>
<ul>
<li><p>Outputs probabilities that sum to 1.</p></li>
</ul>
</li>
<li><p><strong>Cons</strong>:</p>
<ul>
<li><p>Computationally expensive for a large number of classes.</p></li>
</ul>
</li>
</ul>
</section>
<section id="leaky-relu">
<h3>5. <strong>Leaky ReLU</strong><a class="headerlink" href="#leaky-relu" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\( f(x) = x \text{ if } x &gt; 0, \alpha x \text{ if } x \leq 0 \)</span>, where <span class="math notranslate nohighlight">\( \alpha \)</span> is a small positive constant (e.g., 0.01).</p></li>
<li><p><strong>Output Range</strong>: (-<span class="math notranslate nohighlight">\( \infty \)</span>, <span class="math notranslate nohighlight">\( \infty \)</span>)</p></li>
<li><p><strong>Use Case</strong>:</p>
<ul>
<li><p>Mitigates the dead neuron issue in ReLU by allowing small gradients when ( x \leq 0 ).</p></li>
</ul>
</li>
<li><p><strong>Pros</strong>:</p>
<ul>
<li><p>Improves learning in deep networks.</p></li>
</ul>
</li>
<li><p><strong>Cons</strong>:</p>
<ul>
<li><p>Slightly more complex computation than standard ReLU.</p></li>
</ul>
</li>
</ul>
</section>
<section id="choosing-an-activation-function">
<h3><strong>Choosing an Activation Function</strong><a class="headerlink" href="#choosing-an-activation-function" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Hidden Layers</strong>: ReLU or Leaky ReLU are popular choices.</p></li>
<li><p><strong>Output Layer</strong>:</p>
<ul>
<li><p><strong>Binary Classification</strong>: Sigmoid.</p></li>
<li><p><strong>Multi-Class Classification</strong>: Softmax.</p></li>
<li><p><strong>Regression</strong>: Linear activation (no activation).</p></li>
</ul>
</li>
</ul>
<p>Activation functions should be selected based on the problem at hand, as they greatly influence how effectively the network learns and generalizes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Define functions</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">exp_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">exp_x</span> <span class="o">/</span> <span class="n">exp_x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">elu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">swish</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Define input range</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Compute function outputs</span>
<span class="n">functions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Sigmoid&quot;</span><span class="p">:</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
    <span class="s2">&quot;ReLU&quot;</span><span class="p">:</span> <span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
    <span class="s2">&quot;Tanh&quot;</span><span class="p">:</span> <span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
    <span class="s2">&quot;Softmax&quot;</span><span class="p">:</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>  <span class="c1"># Softmax applied to all x values (illustrative purpose)</span>
    <span class="s2">&quot;Leaky ReLU&quot;</span><span class="p">:</span> <span class="n">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
    <span class="s2">&quot;ELU&quot;</span><span class="p">:</span> <span class="n">elu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
<span class="p">}</span>

<span class="c1"># Create plots</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">functions</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Hide any extra subplots (if fewer than 9)</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">functions</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)):</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Activation functions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9717aa4bceef988483029a0c40417685d169e2961110e3a6de01b0b8acafb185.png" src="../_images/9717aa4bceef988483029a0c40417685d169e2961110e3a6de01b0b8acafb185.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Loading and preparing MNIST data</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>  <span class="c1"># Normalizing data</span>

<span class="c1"># Flattening input data</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>

<span class="c1"># List of activation functions to test</span>
<span class="n">activation_functions</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="s1">&#39;swish&#39;</span><span class="p">]</span>
<span class="n">histories</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Function to build and train the model</span>
<span class="k">def</span> <span class="nf">build_and_train_model</span><span class="p">(</span><span class="n">activation</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
        <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,)),</span>
        <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">),</span>
        <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>  <span class="c1"># Output layer</span>
    <span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> 
                  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> 
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">history</span>

<span class="c1"># Training models with different activation functions</span>
<span class="k">for</span> <span class="n">activation</span> <span class="ow">in</span> <span class="n">activation_functions</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training model with activation function: </span><span class="si">{</span><span class="n">activation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">histories</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span> <span class="o">=</span> <span class="n">build_and_train_model</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>

<span class="c1"># Visualizing results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Validation loss plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">activation</span> <span class="ow">in</span> <span class="n">histories</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">histories</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Activation: </span><span class="si">{</span><span class="n">activation</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Validation Loss for Different Activation Functions&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Validation accuracy plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">activation</span> <span class="ow">in</span> <span class="n">histories</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">histories</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Activation: </span><span class="si">{</span><span class="n">activation</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Validation Accuracy for Different Activation Functions&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training model with activation function: relu
Training model with activation function: sigmoid
Training model with activation function: tanh
Training model with activation function: swish
</pre></div>
</div>
<img alt="../_images/b398ac14b9fee8df8f0023eeb224abb98563c99a53609d034f0c1875ca6c189e.png" src="../_images/b398ac14b9fee8df8f0023eeb224abb98563c99a53609d034f0c1875ca6c189e.png" />
</div>
</div>
</section>
</section>
<section id="how-neural-networks-learn">
<h2>How Neural Networks Learn<a class="headerlink" href="#how-neural-networks-learn" title="Permalink to this heading">#</a></h2>
<p>Neural networks learn by iteratively adjusting their internal parameters (weights and biases) to minimize the error in their predictions. This process can be broken down into several key steps:</p>
<section id="forward-propagation">
<h3>1. <strong>Forward Propagation</strong><a class="headerlink" href="#forward-propagation" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Data flows through the network from the input layer, through hidden layers, to the output layer.</p></li>
<li><p>At each neuron, the following operations occur:</p>
<ol class="arabic simple">
<li><p><strong>Weighted Sum</strong>: The neuron computes a weighted sum of its inputs.
$<span class="math notranslate nohighlight">\(
z = \sum (w_i \cdot x_i) + b
\)</span><span class="math notranslate nohighlight">\(
where \)</span> w_i <span class="math notranslate nohighlight">\( are the weights, \)</span> x_i <span class="math notranslate nohighlight">\( are the inputs, and \)</span> b $ is the bias.</p></li>
<li><p><strong>Activation</strong>: The weighted sum is passed through an activation function to introduce non-linearity.</p></li>
</ol>
</li>
<li><p>The output layer produces the final prediction.</p></li>
</ul>
</section>
<section id="loss-function">
<h3>2. <strong>Loss Function</strong><a class="headerlink" href="#loss-function" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The loss function measures how far the network’s predictions are from the true values. Those are actually the same to what we have so far used in regression and classification.</p></li>
<li><p>Common loss functions:</p>
<ul>
<li><p><strong>Mean Squared Error (MSE)</strong>: For regression problems.</p></li>
<li><p><strong>Cross-Entropy Loss</strong>: For classification problems.</p></li>
</ul>
</li>
</ul>
</section>
<section id="backpropagation">
<h3>3. <strong>Backpropagation</strong><a class="headerlink" href="#backpropagation" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Backpropagation calculates how much each weight and bias contributed to the error.</p></li>
<li><p>It uses the <strong>chain rule</strong> of calculus to compute gradients (partial derivatives of the loss function with respect to weights and biases).</p></li>
<li><p>Gradients indicate the direction and magnitude of adjustments needed to reduce the error.</p></li>
</ul>
</section>
<section id="iterative-learning">
<h3>4. <strong>Iterative Learning</strong><a class="headerlink" href="#iterative-learning" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The network repeats forward propagation, loss computation, backpropagation, and gradient descent for multiple iterations (epochs) until:</p>
<ul>
<li><p>The loss function reaches a minimum.</p></li>
<li><p>The network achieves satisfactory accuracy on the training data.</p></li>
</ul>
</li>
</ul>
</section>
<section id="key-concepts">
<h3>5. <strong>Key Concepts</strong><a class="headerlink" href="#key-concepts" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Overfitting</strong>: When the network memorizes training data instead of generalizing to unseen data. Mitigated by techniques like dropout or regularization.</p></li>
<li><p><strong>Learning Rate</strong>: Choosing an appropriate learning rate is critical. Too high causes unstable training; too low leads to slow convergence.</p></li>
</ul>
</section>
<section id="id1">
<h3>Summary<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>Neural networks learn by minimizing the error in predictions through forward propagation, loss computation, backpropagation, and gradient descent. This iterative process enables the network to adjust its internal parameters and improve performance over time.</p>
<p>The network learns as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The neural network starts by making random guesses.

It evaluates how far off the guesses are (like checking how far the dart landed from the target).

It adjusts its aim (weights) to improve over time.
</pre></div>
</div>
</section>
</section>
<section id="example-of-forward-propagation">
<h2>Example of Forward Propagation<a class="headerlink" href="#example-of-forward-propagation" title="Permalink to this heading">#</a></h2>
<section id="problem-statement">
<h3>Problem Statement<a class="headerlink" href="#problem-statement" title="Permalink to this heading">#</a></h3>
<p>We have a simple neural network with:</p>
<ul class="simple">
<li><p><strong>Input Layer</strong>: 2 neurons (<span class="math notranslate nohighlight">\( x_1, x_2 \)</span>)</p></li>
<li><p><strong>Hidden Layer</strong>: 2 neurons (<span class="math notranslate nohighlight">\( h_1, h_2 \)</span>) with a ReLU activation function.</p></li>
<li><p><strong>Output Layer</strong>: 1 neuron (<span class="math notranslate nohighlight">\( y \)</span>) with no activation function.</p></li>
</ul>
</section>
<section id="weights-and-biases">
<h3>Weights and Biases<a class="headerlink" href="#weights-and-biases" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Input to Hidden Layer:</p>
<ul>
<li><p>Weights: <span class="math notranslate nohighlight">\( w_{11}, w_{12}, w_{21}, w_{22} \)</span></p></li>
<li><p>Biases: <span class="math notranslate nohighlight">\( b_1, b_2 \)</span></p></li>
</ul>
</li>
<li><p>Hidden to Output Layer:</p>
<ul>
<li><p>Weights: <span class="math notranslate nohighlight">\( w_{h1}, w_{h2} \)</span></p></li>
<li><p>Bias: <span class="math notranslate nohighlight">\( b_o \)</span></p></li>
</ul>
</li>
</ul>
</section>
<section id="step-by-step-calculation">
<h3>Step-by-Step Calculation<a class="headerlink" href="#step-by-step-calculation" title="Permalink to this heading">#</a></h3>
<section id="inputs">
<h4>1. <strong>Inputs</strong><a class="headerlink" href="#inputs" title="Permalink to this heading">#</a></h4>
<p>Let the inputs be:
$<span class="math notranslate nohighlight">\(
x_1 = 1, \quad x_2 = 2
\)</span>$</p>
</section>
<section id="hidden-layer-calculations">
<h4>2. <strong>Hidden Layer Calculations</strong><a class="headerlink" href="#hidden-layer-calculations" title="Permalink to this heading">#</a></h4>
<p>For each hidden neuron, compute the weighted sum (<span class="math notranslate nohighlight">\( z \)</span>) and apply the ReLU activation:
$<span class="math notranslate nohighlight">\(
z_1 = w_{11} \cdot x_1 + w_{12} \cdot x_2 + b_1
\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(
h_1 = \text{ReLU}(z_1) = \max(0, z_1)
\)</span>$</p>
<div class="math notranslate nohighlight">
\[
z_2 = w_{21} \cdot x_1 + w_{22} \cdot x_2 + b_2
\]</div>
<div class="math notranslate nohighlight">
\[
h_2 = \text{ReLU}(z_2) = \max(0, z_2)
\]</div>
</section>
<section id="output-layer-calculation">
<h4>3. <strong>Output Layer Calculation</strong><a class="headerlink" href="#output-layer-calculation" title="Permalink to this heading">#</a></h4>
<p>Compute the weighted sum of the hidden layer outputs and add the bias:
$<span class="math notranslate nohighlight">\(
y = w_{h1} \cdot h_1 + w_{h2} \cdot h_2 + b_o
\)</span>$</p>
</section>
<section id="example-values">
<h4>4. <strong>Example Values</strong><a class="headerlink" href="#example-values" title="Permalink to this heading">#</a></h4>
<p>Let the weights and biases be:
$<span class="math notranslate nohighlight">\(
w_{11} = 0.5, \quad w_{12} = -0.6, \quad w_{21} = 0.8, \quad w_{22} = 0.1, \quad b_1 = 0.1, \quad b_2 = -0.3
\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(
w_{h1} = 0.7, \quad w_{h2} = -0.4, \quad b_o = 0.2
\)</span>$</p>
<p>Perform the calculations:</p>
<ol class="arabic simple">
<li><p>Hidden Layer:
$<span class="math notranslate nohighlight">\(
z_1 = (0.5 \cdot 1) + (-0.6 \cdot 2) + 0.1 = -0.6
\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(
h_1 = \text{ReLU}(-0.6) = 0
\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(
z_2 = (0.8 \cdot 1) + (0.1 \cdot 2) - 0.3 = 0.7
\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(
h_2 = \text{ReLU}(0.7) = 0.7
\)</span>$</p></li>
<li><p>Output Layer:
$<span class="math notranslate nohighlight">\(
y = (0.7 \cdot 0) + (-0.4 \cdot 0.7) + 0.2 = -0.28
\)</span>$</p></li>
</ol>
</section>
</section>
<section id="final-output">
<h3>Final Output<a class="headerlink" href="#final-output" title="Permalink to this heading">#</a></h3>
<p>The output of the network is:
$<span class="math notranslate nohighlight">\(
y = -0.28
\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="k">as</span> <span class="nn">animation</span>

<span class="c1"># Define the neural network structure</span>
<span class="n">input_neurons</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hidden_neurons</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">output_neurons</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Define weights and biases</span>
<span class="n">weights_input_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">]])</span>
<span class="n">weights_hidden_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.7</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">]])</span>
<span class="n">bias_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
<span class="n">bias_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">])</span>

<span class="c1"># Activation function (ReLU)</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="c1"># Forward propagation function</span>
<span class="k">def</span> <span class="nf">forward_propagation</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">hidden_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights_input_hidden</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias_hidden</span>
    <span class="n">hidden_output</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">hidden_input</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hidden_output</span><span class="p">,</span> <span class="n">weights_hidden_output</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias_output</span>
    <span class="k">return</span> <span class="n">hidden_input</span><span class="p">,</span> <span class="n">hidden_output</span><span class="p">,</span> <span class="n">output</span>

<span class="c1"># Input data</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]])</span>

<span class="c1"># Perform forward propagation</span>
<span class="n">hidden_input</span><span class="p">,</span> <span class="n">hidden_output</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

<span class="c1"># Create the figure</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="c1"># Define positions for the neurons</span>
<span class="n">input_positions</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
<span class="n">hidden_positions</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">output_positions</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

<span class="c1"># Combine all positions</span>
<span class="n">all_positions</span> <span class="o">=</span> <span class="n">input_positions</span> <span class="o">+</span> <span class="n">hidden_positions</span> <span class="o">+</span> <span class="n">output_positions</span>

<span class="c1"># Draw the network</span>
<span class="n">neurons</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">all_positions</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;lightblue&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Draw connections</span>
<span class="n">connections</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_positions</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_positions</span><span class="p">):</span>
        <span class="n">connections</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">],</span> <span class="p">[</span><span class="n">y1</span><span class="p">,</span> <span class="n">y2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_positions</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_positions</span><span class="p">):</span>
        <span class="n">connections</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">],</span> <span class="p">[</span><span class="n">y1</span><span class="p">,</span> <span class="n">y2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Add text labels</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_positions</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Input </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_positions</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Hidden </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_positions</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Output&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Animation function</span>
<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">frame</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">frame</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="c1"># Highlight active connection to hidden neurons</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">connections</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">input_positions</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_positions</span><span class="p">)]):</span>
            <span class="n">line</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_positions</span><span class="p">)</span> <span class="o">==</span> <span class="n">frame</span> <span class="k">else</span> <span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">frame</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="c1"># Highlight active connection to output neurons</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">frame</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">connections</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">input_positions</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_positions</span><span class="p">):]):</span>
            <span class="n">line</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_positions</span><span class="p">)</span> <span class="o">==</span> <span class="n">idx</span> <span class="k">else</span> <span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Reset all connections</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">connections</span><span class="p">:</span>
            <span class="n">line</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="n">ani</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">interval</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">/* Put everything inside the global mpl namespace */
/* global mpl */
window.mpl = {};

mpl.get_websocket_type = function () {
    if (typeof WebSocket !== 'undefined') {
        return WebSocket;
    } else if (typeof MozWebSocket !== 'undefined') {
        return MozWebSocket;
    } else {
        alert(
            'Your browser does not have WebSocket support. ' +
                'Please try Chrome, Safari or Firefox ≥ 6. ' +
                'Firefox 4 and 5 are also supported but you ' +
                'have to enable WebSockets in about:config.'
        );
    }
};

mpl.figure = function (figure_id, websocket, ondownload, parent_element) {
    this.id = figure_id;

    this.ws = websocket;

    this.supports_binary = this.ws.binaryType !== undefined;

    if (!this.supports_binary) {
        var warnings = document.getElementById('mpl-warnings');
        if (warnings) {
            warnings.style.display = 'block';
            warnings.textContent =
                'This browser does not support binary websocket messages. ' +
                'Performance may be slow.';
        }
    }

    this.imageObj = new Image();

    this.context = undefined;
    this.message = undefined;
    this.canvas = undefined;
    this.rubberband_canvas = undefined;
    this.rubberband_context = undefined;
    this.format_dropdown = undefined;

    this.image_mode = 'full';

    this.root = document.createElement('div');
    this.root.setAttribute('style', 'display: inline-block');
    this._root_extra_style(this.root);

    parent_element.appendChild(this.root);

    this._init_header(this);
    this._init_canvas(this);
    this._init_toolbar(this);

    var fig = this;

    this.waiting = false;

    this.ws.onopen = function () {
        fig.send_message('supports_binary', { value: fig.supports_binary });
        fig.send_message('send_image_mode', {});
        if (fig.ratio !== 1) {
            fig.send_message('set_device_pixel_ratio', {
                device_pixel_ratio: fig.ratio,
            });
        }
        fig.send_message('refresh', {});
    };

    this.imageObj.onload = function () {
        if (fig.image_mode === 'full') {
            // Full images could contain transparency (where diff images
            // almost always do), so we need to clear the canvas so that
            // there is no ghosting.
            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);
        }
        fig.context.drawImage(fig.imageObj, 0, 0);
    };

    this.imageObj.onunload = function () {
        fig.ws.close();
    };

    this.ws.onmessage = this._make_on_message_function(this);

    this.ondownload = ondownload;
};

mpl.figure.prototype._init_header = function () {
    var titlebar = document.createElement('div');
    titlebar.classList =
        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';
    var titletext = document.createElement('div');
    titletext.classList = 'ui-dialog-title';
    titletext.setAttribute(
        'style',
        'width: 100%; text-align: center; padding: 3px;'
    );
    titlebar.appendChild(titletext);
    this.root.appendChild(titlebar);
    this.header = titletext;
};

mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};

mpl.figure.prototype._root_extra_style = function (_canvas_div) {};

mpl.figure.prototype._init_canvas = function () {
    var fig = this;

    var canvas_div = (this.canvas_div = document.createElement('div'));
    canvas_div.setAttribute('tabindex', '0');
    canvas_div.setAttribute(
        'style',
        'border: 1px solid #ddd;' +
            'box-sizing: content-box;' +
            'clear: both;' +
            'min-height: 1px;' +
            'min-width: 1px;' +
            'outline: 0;' +
            'overflow: hidden;' +
            'position: relative;' +
            'resize: both;' +
            'z-index: 2;'
    );

    function on_keyboard_event_closure(name) {
        return function (event) {
            return fig.key_event(event, name);
        };
    }

    canvas_div.addEventListener(
        'keydown',
        on_keyboard_event_closure('key_press')
    );
    canvas_div.addEventListener(
        'keyup',
        on_keyboard_event_closure('key_release')
    );

    this._canvas_extra_style(canvas_div);
    this.root.appendChild(canvas_div);

    var canvas = (this.canvas = document.createElement('canvas'));
    canvas.classList.add('mpl-canvas');
    canvas.setAttribute(
        'style',
        'box-sizing: content-box;' +
            'pointer-events: none;' +
            'position: relative;' +
            'z-index: 0;'
    );

    this.context = canvas.getContext('2d');

    var backingStore =
        this.context.backingStorePixelRatio ||
        this.context.webkitBackingStorePixelRatio ||
        this.context.mozBackingStorePixelRatio ||
        this.context.msBackingStorePixelRatio ||
        this.context.oBackingStorePixelRatio ||
        this.context.backingStorePixelRatio ||
        1;

    this.ratio = (window.devicePixelRatio || 1) / backingStore;

    var rubberband_canvas = (this.rubberband_canvas = document.createElement(
        'canvas'
    ));
    rubberband_canvas.setAttribute(
        'style',
        'box-sizing: content-box;' +
            'left: 0;' +
            'pointer-events: none;' +
            'position: absolute;' +
            'top: 0;' +
            'z-index: 1;'
    );

    // Apply a ponyfill if ResizeObserver is not implemented by browser.
    if (this.ResizeObserver === undefined) {
        if (window.ResizeObserver !== undefined) {
            this.ResizeObserver = window.ResizeObserver;
        } else {
            var obs = _JSXTOOLS_RESIZE_OBSERVER({});
            this.ResizeObserver = obs.ResizeObserver;
        }
    }

    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {
        var nentries = entries.length;
        for (var i = 0; i < nentries; i++) {
            var entry = entries[i];
            var width, height;
            if (entry.contentBoxSize) {
                if (entry.contentBoxSize instanceof Array) {
                    // Chrome 84 implements new version of spec.
                    width = entry.contentBoxSize[0].inlineSize;
                    height = entry.contentBoxSize[0].blockSize;
                } else {
                    // Firefox implements old version of spec.
                    width = entry.contentBoxSize.inlineSize;
                    height = entry.contentBoxSize.blockSize;
                }
            } else {
                // Chrome <84 implements even older version of spec.
                width = entry.contentRect.width;
                height = entry.contentRect.height;
            }

            // Keep the size of the canvas and rubber band canvas in sync with
            // the canvas container.
            if (entry.devicePixelContentBoxSize) {
                // Chrome 84 implements new version of spec.
                canvas.setAttribute(
                    'width',
                    entry.devicePixelContentBoxSize[0].inlineSize
                );
                canvas.setAttribute(
                    'height',
                    entry.devicePixelContentBoxSize[0].blockSize
                );
            } else {
                canvas.setAttribute('width', width * fig.ratio);
                canvas.setAttribute('height', height * fig.ratio);
            }
            /* This rescales the canvas back to display pixels, so that it
             * appears correct on HiDPI screens. */
            canvas.style.width = width + 'px';
            canvas.style.height = height + 'px';

            rubberband_canvas.setAttribute('width', width);
            rubberband_canvas.setAttribute('height', height);

            // And update the size in Python. We ignore the initial 0/0 size
            // that occurs as the element is placed into the DOM, which should
            // otherwise not happen due to the minimum size styling.
            if (fig.ws.readyState == 1 && width != 0 && height != 0) {
                fig.request_resize(width, height);
            }
        }
    });
    this.resizeObserverInstance.observe(canvas_div);

    function on_mouse_event_closure(name) {
        /* User Agent sniffing is bad, but WebKit is busted:
         * https://bugs.webkit.org/show_bug.cgi?id=144526
         * https://bugs.webkit.org/show_bug.cgi?id=181818
         * The worst that happens here is that they get an extra browser
         * selection when dragging, if this check fails to catch them.
         */
        var UA = navigator.userAgent;
        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);
        if(isWebKit) {
            return function (event) {
                /* This prevents the web browser from automatically changing to
                 * the text insertion cursor when the button is pressed. We
                 * want to control all of the cursor setting manually through
                 * the 'cursor' event from matplotlib */
                event.preventDefault()
                return fig.mouse_event(event, name);
            };
        } else {
            return function (event) {
                return fig.mouse_event(event, name);
            };
        }
    }

    canvas_div.addEventListener(
        'mousedown',
        on_mouse_event_closure('button_press')
    );
    canvas_div.addEventListener(
        'mouseup',
        on_mouse_event_closure('button_release')
    );
    canvas_div.addEventListener(
        'dblclick',
        on_mouse_event_closure('dblclick')
    );
    // Throttle sequential mouse events to 1 every 20ms.
    canvas_div.addEventListener(
        'mousemove',
        on_mouse_event_closure('motion_notify')
    );

    canvas_div.addEventListener(
        'mouseenter',
        on_mouse_event_closure('figure_enter')
    );
    canvas_div.addEventListener(
        'mouseleave',
        on_mouse_event_closure('figure_leave')
    );

    canvas_div.addEventListener('wheel', function (event) {
        if (event.deltaY < 0) {
            event.step = 1;
        } else {
            event.step = -1;
        }
        on_mouse_event_closure('scroll')(event);
    });

    canvas_div.appendChild(canvas);
    canvas_div.appendChild(rubberband_canvas);

    this.rubberband_context = rubberband_canvas.getContext('2d');
    this.rubberband_context.strokeStyle = '#000000';

    this._resize_canvas = function (width, height, forward) {
        if (forward) {
            canvas_div.style.width = width + 'px';
            canvas_div.style.height = height + 'px';
        }
    };

    // Disable right mouse context menu.
    canvas_div.addEventListener('contextmenu', function (_e) {
        event.preventDefault();
        return false;
    });

    function set_focus() {
        canvas.focus();
        canvas_div.focus();
    }

    window.setTimeout(set_focus, 100);
};

mpl.figure.prototype._init_toolbar = function () {
    var fig = this;

    var toolbar = document.createElement('div');
    toolbar.classList = 'mpl-toolbar';
    this.root.appendChild(toolbar);

    function on_click_closure(name) {
        return function (_event) {
            return fig.toolbar_button_onclick(name);
        };
    }

    function on_mouseover_closure(tooltip) {
        return function (event) {
            if (!event.currentTarget.disabled) {
                return fig.toolbar_button_onmouseover(tooltip);
            }
        };
    }

    fig.buttons = {};
    var buttonGroup = document.createElement('div');
    buttonGroup.classList = 'mpl-button-group';
    for (var toolbar_ind in mpl.toolbar_items) {
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) {
            /* Instead of a spacer, we start a new button group. */
            if (buttonGroup.hasChildNodes()) {
                toolbar.appendChild(buttonGroup);
            }
            buttonGroup = document.createElement('div');
            buttonGroup.classList = 'mpl-button-group';
            continue;
        }

        var button = (fig.buttons[name] = document.createElement('button'));
        button.classList = 'mpl-widget';
        button.setAttribute('role', 'button');
        button.setAttribute('aria-disabled', 'false');
        button.addEventListener('click', on_click_closure(method_name));
        button.addEventListener('mouseover', on_mouseover_closure(tooltip));

        var icon_img = document.createElement('img');
        icon_img.src = '_images/' + image + '.png';
        icon_img.srcset = '_images/' + image + '_large.png 2x';
        icon_img.alt = tooltip;
        button.appendChild(icon_img);

        buttonGroup.appendChild(button);
    }

    if (buttonGroup.hasChildNodes()) {
        toolbar.appendChild(buttonGroup);
    }

    var fmt_picker = document.createElement('select');
    fmt_picker.classList = 'mpl-widget';
    toolbar.appendChild(fmt_picker);
    this.format_dropdown = fmt_picker;

    for (var ind in mpl.extensions) {
        var fmt = mpl.extensions[ind];
        var option = document.createElement('option');
        option.selected = fmt === mpl.default_extension;
        option.innerHTML = fmt;
        fmt_picker.appendChild(option);
    }

    var status_bar = document.createElement('span');
    status_bar.classList = 'mpl-message';
    toolbar.appendChild(status_bar);
    this.message = status_bar;
};

mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {
    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,
    // which will in turn request a refresh of the image.
    this.send_message('resize', { width: x_pixels, height: y_pixels });
};

mpl.figure.prototype.send_message = function (type, properties) {
    properties['type'] = type;
    properties['figure_id'] = this.id;
    this.ws.send(JSON.stringify(properties));
};

mpl.figure.prototype.send_draw_message = function () {
    if (!this.waiting) {
        this.waiting = true;
        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));
    }
};

mpl.figure.prototype.handle_save = function (fig, _msg) {
    var format_dropdown = fig.format_dropdown;
    var format = format_dropdown.options[format_dropdown.selectedIndex].value;
    fig.ondownload(fig, format);
};

mpl.figure.prototype.handle_resize = function (fig, msg) {
    var size = msg['size'];
    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {
        fig._resize_canvas(size[0], size[1], msg['forward']);
        fig.send_message('refresh', {});
    }
};

mpl.figure.prototype.handle_rubberband = function (fig, msg) {
    var x0 = msg['x0'] / fig.ratio;
    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;
    var x1 = msg['x1'] / fig.ratio;
    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;
    x0 = Math.floor(x0) + 0.5;
    y0 = Math.floor(y0) + 0.5;
    x1 = Math.floor(x1) + 0.5;
    y1 = Math.floor(y1) + 0.5;
    var min_x = Math.min(x0, x1);
    var min_y = Math.min(y0, y1);
    var width = Math.abs(x1 - x0);
    var height = Math.abs(y1 - y0);

    fig.rubberband_context.clearRect(
        0,
        0,
        fig.canvas.width / fig.ratio,
        fig.canvas.height / fig.ratio
    );

    fig.rubberband_context.strokeRect(min_x, min_y, width, height);
};

mpl.figure.prototype.handle_figure_label = function (fig, msg) {
    // Updates the figure title.
    fig.header.textContent = msg['label'];
};

mpl.figure.prototype.handle_cursor = function (fig, msg) {
    fig.canvas_div.style.cursor = msg['cursor'];
};

mpl.figure.prototype.handle_message = function (fig, msg) {
    fig.message.textContent = msg['message'];
};

mpl.figure.prototype.handle_draw = function (fig, _msg) {
    // Request the server to send over a new figure.
    fig.send_draw_message();
};

mpl.figure.prototype.handle_image_mode = function (fig, msg) {
    fig.image_mode = msg['mode'];
};

mpl.figure.prototype.handle_history_buttons = function (fig, msg) {
    for (var key in msg) {
        if (!(key in fig.buttons)) {
            continue;
        }
        fig.buttons[key].disabled = !msg[key];
        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);
    }
};

mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {
    if (msg['mode'] === 'PAN') {
        fig.buttons['Pan'].classList.add('active');
        fig.buttons['Zoom'].classList.remove('active');
    } else if (msg['mode'] === 'ZOOM') {
        fig.buttons['Pan'].classList.remove('active');
        fig.buttons['Zoom'].classList.add('active');
    } else {
        fig.buttons['Pan'].classList.remove('active');
        fig.buttons['Zoom'].classList.remove('active');
    }
};

mpl.figure.prototype.updated_canvas_event = function () {
    // Called whenever the canvas gets updated.
    this.send_message('ack', {});
};

// A function to construct a web socket function for onmessage handling.
// Called in the figure constructor.
mpl.figure.prototype._make_on_message_function = function (fig) {
    return function socket_on_message(evt) {
        if (evt.data instanceof Blob) {
            var img = evt.data;
            if (img.type !== 'image/png') {
                /* FIXME: We get "Resource interpreted as Image but
                 * transferred with MIME type text/plain:" errors on
                 * Chrome.  But how to set the MIME type?  It doesn't seem
                 * to be part of the websocket stream */
                img.type = 'image/png';
            }

            /* Free the memory for the previous frames */
            if (fig.imageObj.src) {
                (window.URL || window.webkitURL).revokeObjectURL(
                    fig.imageObj.src
                );
            }

            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(
                img
            );
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        } else if (
            typeof evt.data === 'string' &&
            evt.data.slice(0, 21) === 'data:image/png;base64'
        ) {
            fig.imageObj.src = evt.data;
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        }

        var msg = JSON.parse(evt.data);
        var msg_type = msg['type'];

        // Call the  "handle_{type}" callback, which takes
        // the figure and JSON message as its only arguments.
        try {
            var callback = fig['handle_' + msg_type];
        } catch (e) {
            console.log(
                "No handler for the '" + msg_type + "' message type: ",
                msg
            );
            return;
        }

        if (callback) {
            try {
                // console.log("Handling '" + msg_type + "' message: ", msg);
                callback(fig, msg);
            } catch (e) {
                console.log(
                    "Exception inside the 'handler_" + msg_type + "' callback:",
                    e,
                    e.stack,
                    msg
                );
            }
        }
    };
};

function getModifiers(event) {
    var mods = [];
    if (event.ctrlKey) {
        mods.push('ctrl');
    }
    if (event.altKey) {
        mods.push('alt');
    }
    if (event.shiftKey) {
        mods.push('shift');
    }
    if (event.metaKey) {
        mods.push('meta');
    }
    return mods;
}

/*
 * return a copy of an object with only non-object keys
 * we need this to avoid circular references
 * https://stackoverflow.com/a/24161582/3208463
 */
function simpleKeys(original) {
    return Object.keys(original).reduce(function (obj, key) {
        if (typeof original[key] !== 'object') {
            obj[key] = original[key];
        }
        return obj;
    }, {});
}

mpl.figure.prototype.mouse_event = function (event, name) {
    if (name === 'button_press') {
        this.canvas.focus();
        this.canvas_div.focus();
    }

    // from https://stackoverflow.com/q/1114465
    var boundingRect = this.canvas.getBoundingClientRect();
    var x = (event.clientX - boundingRect.left) * this.ratio;
    var y = (event.clientY - boundingRect.top) * this.ratio;

    this.send_message(name, {
        x: x,
        y: y,
        button: event.button,
        step: event.step,
        modifiers: getModifiers(event),
        guiEvent: simpleKeys(event),
    });

    return false;
};

mpl.figure.prototype._key_event_extra = function (_event, _name) {
    // Handle any extra behaviour associated with a key event
};

mpl.figure.prototype.key_event = function (event, name) {
    // Prevent repeat events
    if (name === 'key_press') {
        if (event.key === this._key) {
            return;
        } else {
            this._key = event.key;
        }
    }
    if (name === 'key_release') {
        this._key = null;
    }

    var value = '';
    if (event.ctrlKey && event.key !== 'Control') {
        value += 'ctrl+';
    }
    else if (event.altKey && event.key !== 'Alt') {
        value += 'alt+';
    }
    else if (event.shiftKey && event.key !== 'Shift') {
        value += 'shift+';
    }

    value += 'k' + event.key;

    this._key_event_extra(event, name);

    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });
    return false;
};

mpl.figure.prototype.toolbar_button_onclick = function (name) {
    if (name === 'download') {
        this.handle_save(this, null);
    } else {
        this.send_message('toolbar_button', { name: name });
    }
};

mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {
    this.message.textContent = tooltip;
};

///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////
// prettier-ignore
var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError("Constructor requires 'new' operator");i.set(this,e)}function h(){throw new TypeError("Function is not a constructor")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line
mpl.toolbar_items = [["Home", "Reset original view", "fa fa-home", "home"], ["Back", "Back to previous view", "fa fa-arrow-left", "back"], ["Forward", "Forward to next view", "fa fa-arrow-right", "forward"], ["", "", "", ""], ["Pan", "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect", "fa fa-arrows", "pan"], ["Zoom", "Zoom to rectangle\nx/y fixes axis", "fa fa-square-o", "zoom"], ["", "", "", ""], ["Download", "Download plot", "fa fa-floppy-o", "download"]];

mpl.extensions = ["eps", "jpeg", "pgf", "pdf", "png", "ps", "raw", "svg", "tif", "webp"];

mpl.default_extension = "png";/* global mpl */

var comm_websocket_adapter = function (comm) {
    // Create a "websocket"-like object which calls the given IPython comm
    // object with the appropriate methods. Currently this is a non binary
    // socket, so there is still some room for performance tuning.
    var ws = {};

    ws.binaryType = comm.kernel.ws.binaryType;
    ws.readyState = comm.kernel.ws.readyState;
    function updateReadyState(_event) {
        if (comm.kernel.ws) {
            ws.readyState = comm.kernel.ws.readyState;
        } else {
            ws.readyState = 3; // Closed state.
        }
    }
    comm.kernel.ws.addEventListener('open', updateReadyState);
    comm.kernel.ws.addEventListener('close', updateReadyState);
    comm.kernel.ws.addEventListener('error', updateReadyState);

    ws.close = function () {
        comm.close();
    };
    ws.send = function (m) {
        //console.log('sending', m);
        comm.send(m);
    };
    // Register the callback with on_msg.
    comm.on_msg(function (msg) {
        //console.log('receiving', msg['content']['data'], msg);
        var data = msg['content']['data'];
        if (data['blob'] !== undefined) {
            data = {
                data: new Blob(msg['buffers'], { type: data['blob'] }),
            };
        }
        // Pass the mpl event to the overridden (by mpl) onmessage function.
        ws.onmessage(data);
    });
    return ws;
};

mpl.mpl_figure_comm = function (comm, msg) {
    // This is the function which gets called when the mpl process
    // starts-up an IPython Comm through the "matplotlib" channel.

    var id = msg.content.data.id;
    // Get hold of the div created by the display call when the Comm
    // socket was opened in Python.
    var element = document.getElementById(id);
    var ws_proxy = comm_websocket_adapter(comm);

    function ondownload(figure, _format) {
        window.open(figure.canvas.toDataURL());
    }

    var fig = new mpl.figure(id, ws_proxy, ondownload, element);

    // Call onopen now - mpl needs it, as it is assuming we've passed it a real
    // web socket which is closed, not our websocket->open comm proxy.
    ws_proxy.onopen();

    fig.parent_element = element;
    fig.cell_info = mpl.find_output_cell("<div id='" + id + "'></div>");
    if (!fig.cell_info) {
        console.error('Failed to find cell for figure', id, fig);
        return;
    }
    fig.cell_info[0].output_area.element.on(
        'cleared',
        { fig: fig },
        fig._remove_fig_handler
    );
};

mpl.figure.prototype.handle_close = function (fig, msg) {
    var width = fig.canvas.width / fig.ratio;
    fig.cell_info[0].output_area.element.off(
        'cleared',
        fig._remove_fig_handler
    );
    fig.resizeObserverInstance.unobserve(fig.canvas_div);

    // Update the output cell to use the data from the current canvas.
    fig.push_to_output();
    var dataURL = fig.canvas.toDataURL();
    // Re-enable the keyboard manager in IPython - without this line, in FF,
    // the notebook keyboard shortcuts fail.
    IPython.keyboard_manager.enable();
    fig.parent_element.innerHTML =
        '<img src="' + dataURL + '" width="' + width + '">';
    fig.close_ws(fig, msg);
};

mpl.figure.prototype.close_ws = function (fig, msg) {
    fig.send_message('closing', msg);
    // fig.ws.close()
};

mpl.figure.prototype.push_to_output = function (_remove_interactive) {
    // Turn the data on the canvas into data in the output cell.
    var width = this.canvas.width / this.ratio;
    var dataURL = this.canvas.toDataURL();
    this.cell_info[1]['text/html'] =
        '<img src="' + dataURL + '" width="' + width + '">';
};

mpl.figure.prototype.updated_canvas_event = function () {
    // Tell IPython that the notebook contents must change.
    IPython.notebook.set_dirty(true);
    this.send_message('ack', {});
    var fig = this;
    // Wait a second, then push the new image to the DOM so
    // that it is saved nicely (might be nice to debounce this).
    setTimeout(function () {
        fig.push_to_output();
    }, 1000);
};

mpl.figure.prototype._init_toolbar = function () {
    var fig = this;

    var toolbar = document.createElement('div');
    toolbar.classList = 'btn-toolbar';
    this.root.appendChild(toolbar);

    function on_click_closure(name) {
        return function (_event) {
            return fig.toolbar_button_onclick(name);
        };
    }

    function on_mouseover_closure(tooltip) {
        return function (event) {
            if (!event.currentTarget.disabled) {
                return fig.toolbar_button_onmouseover(tooltip);
            }
        };
    }

    fig.buttons = {};
    var buttonGroup = document.createElement('div');
    buttonGroup.classList = 'btn-group';
    var button;
    for (var toolbar_ind in mpl.toolbar_items) {
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) {
            /* Instead of a spacer, we start a new button group. */
            if (buttonGroup.hasChildNodes()) {
                toolbar.appendChild(buttonGroup);
            }
            buttonGroup = document.createElement('div');
            buttonGroup.classList = 'btn-group';
            continue;
        }

        button = fig.buttons[name] = document.createElement('button');
        button.classList = 'btn btn-default';
        button.href = '#';
        button.title = name;
        button.innerHTML = '<i class="fa ' + image + ' fa-lg"></i>';
        button.addEventListener('click', on_click_closure(method_name));
        button.addEventListener('mouseover', on_mouseover_closure(tooltip));
        buttonGroup.appendChild(button);
    }

    if (buttonGroup.hasChildNodes()) {
        toolbar.appendChild(buttonGroup);
    }

    // Add the status bar.
    var status_bar = document.createElement('span');
    status_bar.classList = 'mpl-message pull-right';
    toolbar.appendChild(status_bar);
    this.message = status_bar;

    // Add the close button to the window.
    var buttongrp = document.createElement('div');
    buttongrp.classList = 'btn-group inline pull-right';
    button = document.createElement('button');
    button.classList = 'btn btn-mini btn-primary';
    button.href = '#';
    button.title = 'Stop Interaction';
    button.innerHTML = '<i class="fa fa-power-off icon-remove icon-large"></i>';
    button.addEventListener('click', function (_evt) {
        fig.handle_close(fig, {});
    });
    button.addEventListener(
        'mouseover',
        on_mouseover_closure('Stop Interaction')
    );
    buttongrp.appendChild(button);
    var titlebar = this.root.querySelector('.ui-dialog-titlebar');
    titlebar.insertBefore(buttongrp, titlebar.firstChild);
};

mpl.figure.prototype._remove_fig_handler = function (event) {
    var fig = event.data.fig;
    if (event.target !== this) {
        // Ignore bubbled events from children.
        return;
    }
    fig.close_ws(fig, {});
};

mpl.figure.prototype._root_extra_style = function (el) {
    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.
};

mpl.figure.prototype._canvas_extra_style = function (el) {
    // this is important to make the div 'focusable
    el.setAttribute('tabindex', 0);
    // reach out to IPython and tell the keyboard manager to turn it's self
    // off when our div gets focus

    // location in version 3
    if (IPython.notebook.keyboard_manager) {
        IPython.notebook.keyboard_manager.register_events(el);
    } else {
        // location in version 2
        IPython.keyboard_manager.register_events(el);
    }
};

mpl.figure.prototype._key_event_extra = function (event, _name) {
    // Check for shift+enter
    if (event.shiftKey && event.which === 13) {
        this.canvas_div.blur();
        // select the cell after this one
        var index = IPython.notebook.find_cell_index(this.cell_info[0]);
        IPython.notebook.select(index + 1);
    }
};

mpl.figure.prototype.handle_save = function (fig, _msg) {
    fig.ondownload(fig, null);
};

mpl.find_output_cell = function (html_output) {
    // Return the cell and output element which can be found *uniquely* in the notebook.
    // Note - this is a bit hacky, but it is done because the "notebook_saving.Notebook"
    // IPython event is triggered only after the cells have been serialised, which for
    // our purposes (turning an active figure into a static one), is too late.
    var cells = IPython.notebook.get_cells();
    var ncells = cells.length;
    for (var i = 0; i < ncells; i++) {
        var cell = cells[i];
        if (cell.cell_type === 'code') {
            for (var j = 0; j < cell.output_area.outputs.length; j++) {
                var data = cell.output_area.outputs[j];
                if (data.data) {
                    // IPython >= 3 moved mimebundle to data attribute of output
                    data = data.data;
                }
                if (data['text/html'] === html_output) {
                    return [cell, data, j];
                }
            }
        }
    }
};

// Register the function which deals with the matplotlib target/channel.
// The kernel may be null if the page has been refreshed.
if (IPython.notebook.kernel !== null) {
    IPython.notebook.kernel.comm_manager.register_target(
        'matplotlib',
        mpl.mpl_figure_comm
    );
}
</script><div class="output text_html"><img src="data:image/png;base64,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" width="961"></div></div>
</div>
</section>
<section id="id2">
<h3>Backpropagation<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>The idea of backpropagation is to allow the network to “learn”. Backpropagation (short for “backward propagation of errors”) is an optimization algorithm that computes the gradient of the loss function with respect to each weight and bias in the network. It ensures that weights are updated in the direction that reduces the error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># Step 1: Load the Iris Dataset</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># Features (sepal length, sepal width, petal length, petal width)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># Target (species: 0, 1, 2)</span>

<span class="c1"># Step 2: Split the Dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Step 3: Standardize the Features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Step 4: Create and Train the Neural Network</span>
<span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Step 5: Make Predictions</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">mlp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Step 6: Evaluate the Model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">))</span>

<span class="c1"># Step 7: Visualize the Decision Boundary (Using First Two Features for Simplicity)</span>
<span class="k">def</span> <span class="nf">plot_decision_boundary</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span>
                         <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">))</span>

    <span class="n">Z</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Decision Boundary&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 2&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Reduce to First Two Features for Visualization</span>
<span class="n">X_train_vis</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">X_test_vis</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">mlp_vis</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">mlp_vis</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_vis</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Plot Decision Boundary</span>
<span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">X_test_vis</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">mlp_vis</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion Matrix:
[[15  0  0]
 [ 0 14  1]
 [ 0  3 12]]

Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        15
  versicolor       0.82      0.93      0.88        15
   virginica       0.92      0.80      0.86        15

    accuracy                           0.91        45
   macro avg       0.92      0.91      0.91        45
weighted avg       0.92      0.91      0.91        45
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="advanced-neural-network-architectures-rnns-and-cnns">
<h2>Advanced Neural Network Architectures: RNNs and CNNs<a class="headerlink" href="#advanced-neural-network-architectures-rnns-and-cnns" title="Permalink to this heading">#</a></h2>
<section id="convolutional-neural-networks-cnns">
<h3>1. <strong>Convolutional Neural Networks (CNNs)</strong><a class="headerlink" href="#convolutional-neural-networks-cnns" title="Permalink to this heading">#</a></h3>
<p><strong>Purpose</strong>: Designed for image and spatial data processing.</p>
<section id="key-components">
<h4>Key Components:<a class="headerlink" href="#key-components" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Convolution Layers</strong>:</p>
<ul>
<li><p>Detect patterns such as edges, textures, or objects in an image.</p></li>
<li><p>Apply a small filter (kernel) over the input to create feature maps.</p></li>
</ul>
</li>
<li><p><strong>Pooling Layers</strong>:</p>
<ul>
<li><p>Reduce the spatial dimensions of feature maps, retaining important information.</p></li>
<li><p>Common pooling methods: Max Pooling, Average Pooling.</p></li>
</ul>
</li>
<li><p><strong>Fully Connected Layers</strong>:</p>
<ul>
<li><p>Combine extracted features to classify or predict outcomes.</p></li>
</ul>
</li>
<li><p><strong>Activation Functions</strong>:</p>
<ul>
<li><p>Often ReLU (Rectified Linear Unit) is used for non-linearity.</p></li>
</ul>
</li>
</ul>
</section>
<section id="example-architecture">
<h4>Example Architecture:<a class="headerlink" href="#example-architecture" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>Input Layer</strong>: Takes an image (e.g., 28x28 pixels for MNIST).</p></li>
<li><p><strong>Convolution Layer</strong>: Applies filters to extract local patterns.</p></li>
<li><p><strong>Pooling Layer</strong>: Down-samples feature maps to reduce complexity.</p></li>
<li><p><strong>Convolution + Pooling Layers</strong>: Repeat for deeper feature extraction.</p></li>
<li><p><strong>Fully Connected Layer</strong>: Maps features to output classes.</p></li>
</ol>
</section>
<section id="use-cases">
<h4>Use Cases:<a class="headerlink" href="#use-cases" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Image Classification</strong>: Identifying objects in an image (e.g., cats vs. dogs).</p></li>
<li><p><strong>Object Detection</strong>: Locating objects in an image (e.g., bounding boxes).</p></li>
<li><p><strong>Medical Imaging</strong>: Detecting diseases from X-rays or MRIs.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="recurrent-neural-networks-rnns">
<h3>2. <strong>Recurrent Neural Networks (RNNs)</strong><a class="headerlink" href="#recurrent-neural-networks-rnns" title="Permalink to this heading">#</a></h3>
<p><strong>Purpose</strong>: Designed for sequential and time-series data processing.</p>
<section id="id3">
<h4>Key Components:<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Recurrent Connections</strong>:</p>
<ul>
<li><p>Each neuron remembers information from the previous time step.</p></li>
<li><p>Creates a loop that passes information forward in the sequence.</p></li>
</ul>
</li>
<li><p><strong>Hidden State</strong>:</p>
<ul>
<li><p>Maintains context from previous inputs, enabling sequence learning.</p></li>
</ul>
</li>
<li><p><strong>Variants</strong>:</p>
<ul>
<li><p><strong>LSTMs (Long Short-Term Memory)</strong>: Mitigate vanishing gradients with gates that control information flow.</p></li>
<li><p><strong>GRUs (Gated Recurrent Units)</strong>: Similar to LSTMs but with fewer parameters.</p></li>
</ul>
</li>
</ul>
</section>
<section id="id4">
<h4>Example Architecture:<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>Input Layer</strong>: Sequential data (e.g., text or stock prices).</p></li>
<li><p><strong>RNN/LSTM/GRU Layer</strong>: Processes the sequence one step at a time.</p></li>
<li><p><strong>Fully Connected Layer</strong>: Maps the sequence to a target output.</p></li>
</ol>
</section>
<section id="id5">
<h4>Use Cases:<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Natural Language Processing</strong>: Language modeling, translation, sentiment analysis.</p></li>
<li><p><strong>Time-Series Prediction</strong>: Forecasting stock prices or weather patterns.</p></li>
<li><p><strong>Speech Recognition</strong>: Converting spoken words to text.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="differences-between-cnns-and-rnns">
<h3>3. <strong>Differences Between CNNs and RNNs</strong><a class="headerlink" href="#differences-between-cnns-and-rnns" title="Permalink to this heading">#</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Feature</p></th>
<th class="head"><p>CNN</p></th>
<th class="head"><p>RNN</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Input Type</strong></p></td>
<td><p>Images, spatial data</p></td>
<td><p>Sequential, temporal data</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Structure</strong></p></td>
<td><p>Hierarchical layers</p></td>
<td><p>Recurrence with loops</p></td>
</tr>
<tr class="row-even"><td><p><strong>Key Strength</strong></p></td>
<td><p>Captures spatial patterns</p></td>
<td><p>Learns temporal dependencies</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Example Applications</strong></p></td>
<td><p>Image classification, object detection</p></td>
<td><p>Language modeling, time-series prediction</p></td>
</tr>
</tbody>
</table>
</section>
<hr class="docutils" />
<section id="combined-architectures">
<h3>4. <strong>Combined Architectures</strong><a class="headerlink" href="#combined-architectures" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>CNN + RNN</strong>:</p>
<ul>
<li><p>Combine CNNs for feature extraction and RNNs for sequence modeling.</p></li>
<li><p><strong>Example</strong>: Video analysis (CNN for spatial features, RNN for temporal patterns).</p></li>
</ul>
</li>
<li><p><strong>CNN + Fully Connected</strong>:</p>
<ul>
<li><p>Used in tasks like image classification where the CNN extracts features and the fully connected layer classifies.</p></li>
</ul>
</li>
</ul>
<p>These architectures represent specialized neural networks tailored to solve complex real-world problems effectively.</p>
<img src='img/CNN.png' />
<img src='img/RNN.png' /></section>
</section>
<section id="challenges-and-limitations-of-neural-networks">
<h2>Challenges and Limitations of Neural Networks<a class="headerlink" href="#challenges-and-limitations-of-neural-networks" title="Permalink to this heading">#</a></h2>
<p>While neural networks are powerful tools for solving complex problems, they are not without challenges and limitations. Understanding these can help in designing better models and managing expectations.</p>
<hr class="docutils" />
<section id="data-requirements">
<h3>1. <strong>Data Requirements</strong><a class="headerlink" href="#data-requirements" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Neural networks require large amounts of high-quality labeled data to train effectively.</p></li>
<li><p><strong>Example</strong>: Image classification tasks often need thousands of labeled images for each category.</p></li>
<li><p><strong>Challenge</strong>: Acquiring and labeling such datasets can be expensive and time-consuming.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="computational-cost">
<h3>2. <strong>Computational Cost</strong><a class="headerlink" href="#computational-cost" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Neural networks, especially deep networks, are computationally intensive to train.</p></li>
<li><p><strong>Hardware Requirements</strong>:</p>
<ul>
<li><p>Training models often requires GPUs or TPUs for parallel processing.</p></li>
</ul>
</li>
<li><p><strong>Challenge</strong>: High computational costs can limit accessibility for individuals or organizations without significant resources.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="overfitting">
<h3>3. <strong>Overfitting</strong><a class="headerlink" href="#overfitting" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Neural networks can memorize training data rather than generalizing to unseen data.</p></li>
<li><p><strong>Example</strong>: A network might achieve near-perfect accuracy on training data but fail on test data.</p></li>
<li><p><strong>Solution</strong>: Techniques like regularization, dropout, and early stopping are used to mitigate this.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="black-box-nature">
<h3>4. <strong>Black Box Nature</strong><a class="headerlink" href="#black-box-nature" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Neural networks are often criticized for their lack of interpretability.</p></li>
<li><p><strong>Problem</strong>: It is difficult to understand how a neural network arrives at a decision, especially in critical areas like healthcare or finance.</p></li>
<li><p><strong>Emerging Solutions</strong>: Explainable AI (XAI) and visualization tools aim to make models more transparent.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="hyperparameter-sensitivity">
<h3>5. <strong>Hyperparameter Sensitivity</strong><a class="headerlink" href="#hyperparameter-sensitivity" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Neural networks require careful tuning of hyperparameters such as learning rate, number of layers, and neurons.</p></li>
<li><p><strong>Challenge</strong>: Finding the optimal combination often involves trial-and-error or computationally expensive optimization techniques.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="energy-consumption">
<h3>6. <strong>Energy Consumption</strong><a class="headerlink" href="#energy-consumption" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Training large neural networks can consume significant energy, contributing to environmental concerns.</p></li>
<li><p><strong>Example</strong>: Training a single large language model can have a carbon footprint comparable to multiple transatlantic flights.</p></li>
<li><p><strong>Solution</strong>: Research into efficient algorithms and hardware can help reduce energy usage.</p></li>
</ul>
</section>
<section id="id6">
<h3>Summary<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>Neural networks are powerful machine learning tools inspired by the human brain, capable of solving complex problems across various domains. They consist of interconnected layers of artificial neurons, with each layer progressively transforming input data to produce meaningful outputs. These architectures range from simple feedforward networks to advanced designs like Convolutional Neural Networks (CNNs) for image processing and Recurrent Neural Networks (RNNs) for sequential data.</p>
<p>The strength of neural networks lies in their ability to learn from data, adapt to various tasks, and make predictions or classifications with high accuracy. They are widely used in real-world applications such as image recognition, natural language processing, autonomous vehicles, and healthcare.</p>
<p>However, neural networks come with challenges:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>High Data and Computational Requirements: Training deep networks demands large datasets and substantial computational resources.

Overfitting and Bias: Ensuring generalization and fairness requires careful data preparation and model tuning.

Interpretability: Their “black box” nature makes understanding decision-making processes difficult, particularly in critical applications.

Energy and Environmental Impact: Training large models can be resource-intensive, prompting a need for sustainable solutions.
</pre></div>
</div>
<p>Despite these limitations, advancements in techniques like regularization, explainable AI, and efficient hardware continue to address these challenges, making neural networks more accessible, robust, and interpretable.</p>
<p>By understanding their architecture, learning process, and limitations, we can better harness the power of neural networks for solving real-world problems and driving innovation across industries.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./_sources"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-neural-networks">What Are Neural Networks?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-are-neural-networks-important">Why Are Neural Networks Important?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-they-work-high-level-overview">How Do They Work? (High-Level Overview)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-features">Key Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-are-neural-network-used">Where are Neural Network used?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-blocks-of-a-neural-network">Building Blocks of a Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-data-flows">How Data Flows</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-neural-network-architecture-impacts-predictions">How Neural Network Architecture Impacts Predictions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-layers">1. <strong>Number of Layers</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-neurons-in-each-layer">2. <strong>Number of Neurons in Each Layer</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#choice-of-activation-functions">3. <strong>Choice of Activation Functions</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-techniques">4. <strong>Regularization Techniques</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#depth-vs-breadth">5. <strong>Depth vs. Breadth</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connectivity-and-architecture">6. <strong>Connectivity and Architecture</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary"><strong>Summary</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-activation-functions">Common Activation Functions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sigmoid-function">1. <strong>Sigmoid Function</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relu-rectified-linear-unit">2. <strong>ReLU (Rectified Linear Unit)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tanh-hyperbolic-tangent">3. <strong>Tanh (Hyperbolic Tangent)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-function">4. <strong>Softmax Function</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#leaky-relu">5. <strong>Leaky ReLU</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-an-activation-function"><strong>Choosing an Activation Function</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-neural-networks-learn">How Neural Networks Learn</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-propagation">1. <strong>Forward Propagation</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">2. <strong>Loss Function</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation">3. <strong>Backpropagation</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iterative-learning">4. <strong>Iterative Learning</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">5. <strong>Key Concepts</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-of-forward-propagation">Example of Forward Propagation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weights-and-biases">Weights and Biases</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-calculation">Step-by-Step Calculation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#inputs">1. <strong>Inputs</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hidden-layer-calculations">2. <strong>Hidden Layer Calculations</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#output-layer-calculation">3. <strong>Output Layer Calculation</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-values">4. <strong>Example Values</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-output">Final Output</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Backpropagation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-neural-network-architectures-rnns-and-cnns">Advanced Neural Network Architectures: RNNs and CNNs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-neural-networks-cnns">1. <strong>Convolutional Neural Networks (CNNs)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-components">Key Components:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-architecture">Example Architecture:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#use-cases">Use Cases:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-neural-networks-rnns">2. <strong>Recurrent Neural Networks (RNNs)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Key Components:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Example Architecture:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Use Cases:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differences-between-cnns-and-rnns">3. <strong>Differences Between CNNs and RNNs</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#combined-architectures">4. <strong>Combined Architectures</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-limitations-of-neural-networks">Challenges and Limitations of Neural Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-requirements">1. <strong>Data Requirements</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-cost">2. <strong>Computational Cost</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting">3. <strong>Overfitting</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#black-box-nature">4. <strong>Black Box Nature</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-sensitivity">5. <strong>Hyperparameter Sensitivity</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#energy-consumption">6. <strong>Energy Consumption</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Summary</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Radosław Zajdel
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>