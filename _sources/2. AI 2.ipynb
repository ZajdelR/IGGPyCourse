{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eda6489",
   "metadata": {},
   "source": [
    "# Lecture 2: Introduction to Machine Learning tasks and intuition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbece3",
   "metadata": {},
   "source": [
    "## Quick recap:\n",
    "\n",
    "<b> The goal of AI is to build a being that reasons like a human. </b>\n",
    "\n",
    "Altough in many tasks these algorithms already surpass human abilities, these are bad at generlising tasks, being trained to do single thing only. But, we are getting better.\n",
    "\n",
    "### Machine learning defintion\n",
    "\n",
    "Machine learning is a model learning from experience E to perform task T evaluating its performance through a measure P.\n",
    "\n",
    "\n",
    "### Model development process\n",
    "\n",
    "The whole process of developing machine learning solutions is complex and involves multiple steps.\n",
    "\n",
    "<img src='img/flow.jpg' width=550/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4bebb",
   "metadata": {},
   "source": [
    "## Types of machine learning algorithms\n",
    "\n",
    "<img src='img/typesofml.jpg' />\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "Definition: Learning from labeled data, where the input-output pairs are provided.\n",
    "Goal: Predict output values for new data.\n",
    "Types:\n",
    "\n",
    "* Regression: Predict continuous outputs.\n",
    "        Example: Predicting house prices.\n",
    "* Classification: Predict categorical outputs.\n",
    "        Example: Email spam detection.\n",
    "        \n",
    "### Unsupervised learning\n",
    "\n",
    "Definition: Learning from data that is not labeled, finding patterns or structure in the data.\n",
    "Goal: Group data points, reduce data dimensions, or discover associations.\n",
    "Types:\n",
    "\n",
    "* Clustering: Group similar data points together.\n",
    "        Example: Customer segmentation.\n",
    "        \n",
    "* Association: Find rules that describe large portions of the data.\n",
    "        Example: Market basket analysis.\n",
    "       \n",
    "* Dimensionality Reduction: Limit the number of variables describing the data to minimum.\n",
    "    \n",
    "        Example: Decide which variables are the most important to predict who will buy certain products in a shop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f7f38",
   "metadata": {},
   "source": [
    "## Probability: at the core of Machine Learning\n",
    "\n",
    "### What is probability?\n",
    "\n",
    "Probability is a way of measuring the likelihood of an event happening.\n",
    "It ranges between 0 (impossible event) and 1 (certain event).\n",
    "\n",
    "Probability of something happening half the times is 0.5 (or 50%, but we prefer the decimal expression).\n",
    "\n",
    "### Random variable\n",
    "\n",
    "A random variable is a variable that can take different values, each with a certain probability.\n",
    "\n",
    "For example: a dice roll. It can be either 1, 2, 3, 4, 5 or 6. The random variable X is the outcome of the roll, therefore\n",
    "\n",
    "P(X=x) = 1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f8e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b961e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(np.random.randint(0,2,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ee5eb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5001\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x in data:\n",
    "    if x == 1:\n",
    "        counter += 1\n",
    "print(counter/number_of_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cab58f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_datapoints = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59cf4ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1def40",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "a[0] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb1d855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3eb3c6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfb3aae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f310823",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03f2263df154fd4ad8aa47cc8378fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Number of Rolls', max=10000, min=1, step=10), Output()),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Function to simulate dice rolls and plot the distribution\n",
    "def plot_dice_rolls(num_rolls=10):\n",
    "    # Simulate dice rolls (values between 1 and 6)\n",
    "    rolls = np.random.randint(1, 7, size=num_rolls)\n",
    "    \n",
    "    # Calculate the frequency of each outcome (1 to 6)\n",
    "    counts, bins = np.histogram(rolls, bins=np.arange(1, 8), density=True)\n",
    "    \n",
    "    # Plot the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(bins[:-1], counts, width=0.6, color='blue', alpha=0.7, edgecolor='black')\n",
    "    plt.xticks(np.arange(1, 7))\n",
    "    \n",
    "    # Plotting the theoretical uniform distribution line for comparison\n",
    "    plt.axhline(1/6, color='red', linestyle='--', label='Theoretical Probability (1/6)')\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.title(f'Distribution of Dice Rolls (n={num_rolls})')\n",
    "    plt.xlabel('Dice Face')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Creating an interactive slider for the number of dice rolls\n",
    "interact(plot_dice_rolls, \n",
    "         num_rolls=widgets.IntSlider(min=1, max=10_000, step=10, value=1, description='Number of Rolls'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391f5331",
   "metadata": {},
   "source": [
    "### Other examples of probability\n",
    "\n",
    "We find probability to be useful in many examples, such as games. \n",
    "\n",
    "Probability of geting a pair in the poker: 42.26%\n",
    "\n",
    "    Getting a three of a kind: 2.11%\n",
    "    Full House: 0.144%\n",
    "    Flush: 0.198%\n",
    "    Full poker: 0.024%\n",
    "\n",
    "And the probability to winn the lottery (where you have to correctly guess 6 out of 49 numbers) is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54f2583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(x)=0.0000000715%\n"
     ]
    }
   ],
   "source": [
    "import scipy.special\n",
    "\n",
    "x = 1/(scipy.special.binom(49, 6))\n",
    "print(f'P(x)={x:.10f}%'.format(x*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e9389",
   "metadata": {},
   "source": [
    "Probability is **why casino always wins**. Let's say we have a roulette\n",
    "\n",
    "<img src='img/roulette.jpg' />\n",
    "\n",
    "We have 37 fields, 18 red, 18 black, 1 green.\n",
    "\n",
    "Betting all on red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad6bedb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.64864864864865"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(18/37)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6067473b",
   "metadata": {},
   "source": [
    "Hence, the probability that casino wins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec27412f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.35135135135135"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(19/37)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6298e37d",
   "metadata": {},
   "source": [
    "Casino use probability to earn money. **Odds are always in the favor of casino.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e174670",
   "metadata": {},
   "source": [
    "### Probability distributions\n",
    "\n",
    "A probability distribution tells us the probability of each possible outcome for a random variable.\n",
    "\n",
    "Example: Rolling a fair dice has a uniform distribution, where each outcome (1 to 6) is equally likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8302a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b15588fc5e4351a9f652fa40453950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Distribution', options=('Normal', 'Uniform', 'Binomial', 'Poisson'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Function to plot different distributions as bar plots based on user selection\n",
    "def plot_distribution(distribution, param1, param2):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Choose the distribution to plot\n",
    "    if distribution == 'Normal':\n",
    "        # Generate random samples from a normal distribution\n",
    "        samples = np.random.normal(param1, param2, 1000)\n",
    "        # Plot histogram as bar plot\n",
    "        plt.hist(samples, bins=20, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "        plt.title(f'Normal Distribution\\nMean = {param1}, Std Dev = {param2}')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Probability Density')\n",
    "        \n",
    "    elif distribution == 'Uniform':\n",
    "        # Generate random samples from a uniform distribution\n",
    "        samples = np.random.uniform(param1, param2, 1000)\n",
    "        # Plot histogram as bar plot\n",
    "        plt.hist(samples, bins=20, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "        plt.title(f'Uniform Distribution\\nRange = [{param1}, {param2}]')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Probability Density')\n",
    "        \n",
    "    elif distribution == 'Binomial':\n",
    "        # Generate random samples from a binomial distribution\n",
    "        samples = np.random.binomial(param1, param2, 1000)\n",
    "        # Plot histogram as bar plot\n",
    "        plt.hist(samples, bins=np.arange(0, param1+2) - 0.5, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "        plt.title(f'Binomial Distribution\\nTrials = {param1}, Probability = {param2}')\n",
    "        plt.xlabel('Number of Successes')\n",
    "        plt.ylabel('Probability')\n",
    "        \n",
    "    elif distribution == 'Poisson':\n",
    "        # Generate random samples from a Poisson distribution\n",
    "        samples = np.random.poisson(param1, 1000)\n",
    "        # Plot histogram as bar plot\n",
    "        plt.hist(samples, bins=np.arange(0, np.max(samples)+1) - 0.5, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "        plt.title(f'Poisson Distribution\\nLambda = {param1}')\n",
    "        plt.xlabel('Number of Events')\n",
    "        plt.ylabel('Probability')\n",
    "        \n",
    "    # Show the plot\n",
    "    plt.xlim(0,100)\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widgets to switch between distributions and adjust parameters\n",
    "distribution_dropdown = widgets.Dropdown(\n",
    "    options=['Normal', 'Uniform', 'Binomial', 'Poisson'],\n",
    "    value='Normal',\n",
    "    description='Distribution'\n",
    ")\n",
    "\n",
    "# Parameters for the different distributions\n",
    "param1_slider = widgets.FloatSlider(min=0, max=10, step=0.1, value=5, description='Param1')\n",
    "param2_slider = widgets.FloatSlider(min=0.1, max=5, step=0.1, value=1, description='Param2')\n",
    "\n",
    "# Update the sliders based on the chosen distribution\n",
    "def update_parameters(distribution):\n",
    "    if distribution == 'Normal':\n",
    "        param1_slider.description = 'Mean'\n",
    "        param2_slider.description = 'Std Dev'\n",
    "        param1_slider.min = -10\n",
    "        param1_slider.max = 10\n",
    "        param2_slider.min = 0.1\n",
    "        param2_slider.max = 5\n",
    "    elif distribution == 'Uniform':\n",
    "        param1_slider.description = 'Min'\n",
    "        param2_slider.description = 'Max'\n",
    "        param1_slider.min = -10\n",
    "        param1_slider.max = 10\n",
    "        param2_slider.min = -10\n",
    "        param2_slider.max = 10\n",
    "    elif distribution == 'Binomial':\n",
    "        param1_slider.description = 'Trials'\n",
    "        param2_slider.description = 'Probability'\n",
    "        param1_slider.min = 1\n",
    "        param1_slider.max = 100\n",
    "        param2_slider.min = 0.01\n",
    "        param2_slider.max = 1\n",
    "    elif distribution == 'Poisson':\n",
    "        param1_slider.description = 'Lambda'\n",
    "        param2_slider.description = 'Unused'\n",
    "        param2_slider.value = 0  # Not used in Poisson, but needed for the function\n",
    "        param2_slider.layout.display = 'none'  # Hide the second parameter slider\n",
    "\n",
    "# Function to handle changes in distribution dropdown\n",
    "def update_distribution(change):\n",
    "    update_parameters(change['new'])\n",
    "\n",
    "# Link the update function to the dropdown change event\n",
    "distribution_dropdown.observe(update_distribution, names='value')\n",
    "\n",
    "# Display interactive plot with widgets\n",
    "interact(plot_distribution, \n",
    "         distribution=distribution_dropdown,\n",
    "         param1=param1_slider,\n",
    "         param2=param2_slider);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a847348",
   "metadata": {},
   "source": [
    "### Normal distribution\n",
    "\n",
    "Normal distribution  (also called the Gaussian Distribution) is the most common distribution type. It describe a probability of random incident happening.\n",
    "\n",
    "The **mean** (average) defines the center of the distribution, while the **standard deviation** defines the spread or width of the curve.\n",
    "\n",
    "Many natural phenomena are Normally Distributed:\n",
    "\n",
    "* Many real-world data sets follow a normal distribution, such as heights, test scores, or measurement errors.\n",
    "* Machine learning often works with natural data, making the normal distribution an important assumption for many models.\n",
    "\n",
    "Central Limit Theorem (CLT):\n",
    "\n",
    "The Central Limit Theorem states that the sum or average of a large number of independent random variables, regardless of their original distribution, will be approximately normally distributed.\n",
    "\n",
    "\n",
    "Outlier Detection:\n",
    "\n",
    "When we try to identify if our data is **correct** and we <i>know</i> that data is normally distributed. We can use the distribution to asses if our data has incorrect measurments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00556b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6333df0b73843c08883a630dedbed17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Mean', max=10.0, min=-10.0), FloatSlider(value=1.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Function to calculate and plot the probability density function (PDF)\n",
    "def plot_normal_distribution(mean=0, std_dev=1):\n",
    "    # Generate a range of x values\n",
    "    x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 1000)\n",
    "    \n",
    "    # Calculate the PDF using the mean and standard deviation\n",
    "    y = norm.pdf(x, mean, std_dev)\n",
    "    \n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y, label=f'Normal Distribution\\nMean = {mean}, Std Dev = {std_dev}')\n",
    "    plt.fill_between(x, y, alpha=0.2)\n",
    "    \n",
    "    # Highlighting the area under the curve between -1 std and +1 std\n",
    "    x_fill = np.linspace(mean - std_dev, mean + std_dev, 1000)\n",
    "    y_fill = norm.pdf(x_fill, mean, std_dev)\n",
    "    plt.fill_between(x_fill, y_fill, color='red', alpha=0.3, label='1 Std Dev Range')\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.title('Probability Density Function (Normal Distribution)')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.legend()\n",
    "    plt.xlim(-10,10)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Creating interactive sliders for mean and standard deviation\n",
    "interact(plot_normal_distribution, \n",
    "         mean=widgets.FloatSlider(min=-10, max=10, step=0.1, value=0, description='Mean'),\n",
    "         std_dev=widgets.FloatSlider(min=0.1, max=5, step=0.1, value=1, description='Std Dev'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243f8d1",
   "metadata": {},
   "source": [
    "### Joint, Marginal, and Conditional Probability\n",
    "\n",
    "Joint probability is the probability that two events happen at the same time.\n",
    "    \n",
    "    P(A∩B) is the probability that both A and B occur.\n",
    "\n",
    "For example, to get an answer on the test right picking it at random (let's say there are four A, B, C, D) is P(x) = 1/4 = 25%\n",
    "\n",
    "To get two of them right at the same time is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "032d9a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.25"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/4 * 1/4)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787dc6d",
   "metadata": {},
   "source": [
    "To get 50 questions right at the same time on random is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1e06eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.25"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/4**2)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d10f19",
   "metadata": {},
   "source": [
    "Marginal probability is the probability of the single event happening.\n",
    "\n",
    "Conditional Probability is the robability of an event occurring given that another event has occurred.\n",
    "\n",
    "    P(A∣B) is the probability of event A happening, given that B has occurred.\n",
    "    \n",
    "Let's say we have the sequence of symbols:\n",
    "\n",
    "[1 2 1 2 1 3]\n",
    "\n",
    "What is the probability that after 1, 2 will appear?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46bfe17",
   "metadata": {},
   "source": [
    "### Monty Hall problem\n",
    "\n",
    "Given three gates a contenstant have to pick a gate. One of them have a car behind, other two hide goats behind them.\n",
    "\n",
    "What is the probability of selecting the right gate?\n",
    "\n",
    "1/3 - 1 of 3 three gates has the price.\n",
    "\n",
    "You pick a gate, say 1, nd the host, who knows what's behind the doors, opens another door, say No. 3, which has a goat.\n",
    "\n",
    "You then are given a choice, do you want to stay or do you want to switch? What should you do?\n",
    "\n",
    "\n",
    "When the player first chooses a gate, there is 2/3 chance that the car is behind door **NOT** chosen. This probability stays the same, when other gate is opened.\n",
    "\n",
    "When wrong doors were revealed, you *learned* that this 2/3 chance lies on the other gate, gate No. 2., which you haven't pick at the start.\n",
    "\n",
    "**It feels counterintuitive**, because we feel that it does not matter which one we pick, there is always 1/3 chance we get the door right.\n",
    "\n",
    "But the host revaled the information that one of gates not choosen there is a goat. It changed the marginal probability into the conditional probability:\n",
    "\n",
    "Initially there is:\n",
    "\n",
    "    P(Car behind Door 1) = 1/3\n",
    "    P(Car behind Door 2) = 1/3\n",
    "    P(Car behind Door 3) = 1/3\n",
    "\n",
    "But when the host opened the doors it switched the probabilities into:\n",
    "\n",
    "     P(Car behind Door 1) = 1/3\n",
    "     P(Car behind Door 2|goat behind Door 3) = 2/3\n",
    "     \n",
    "**New information updates probabilities**\n",
    "\n",
    "\n",
    "If you still don't belive me, let's simulate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a426dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def monty_hall_simulation(trials, switch=True):\n",
    "    wins = 0\n",
    "    \n",
    "    for _ in range(trials):\n",
    "        # Randomly assign the car (1) and the goats (0) behind the doors\n",
    "        doors = [0, 0, 1]\n",
    "        random.shuffle(doors)\n",
    "        \n",
    "        # Contestant makes a random choice\n",
    "        initial_choice = random.randint(0, 2)\n",
    "        \n",
    "        # Host opens a door that has a goat (not the contestant's choice and not the car)\n",
    "        available_doors = [i for i in range(3) if i != initial_choice and doors[i] == 0]\n",
    "        host_opens = random.choice(available_doors)\n",
    "        \n",
    "        # If the contestant switches, choose the remaining door\n",
    "        if switch:\n",
    "            final_choice = [i for i in range(3) if i != initial_choice and i != host_opens][0]\n",
    "        else:\n",
    "            final_choice = initial_choice\n",
    "        \n",
    "        # Count wins\n",
    "        if doors[final_choice] == 1:\n",
    "            wins += 1\n",
    "    \n",
    "    return wins / trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "346c26a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate when switching: 66.66%\n",
      "Win rate when not switching: 33.47%\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "trials = 100_000\n",
    "\n",
    "# Simulate both strategies\n",
    "win_rate_with_switch = monty_hall_simulation(trials, switch=True)\n",
    "win_rate_without_switch = monty_hall_simulation(trials, switch=False)\n",
    "\n",
    "print(f\"Win rate when switching: {win_rate_with_switch:.2%}\")\n",
    "print(f\"Win rate when not switching: {win_rate_without_switch:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d1f28",
   "metadata": {},
   "source": [
    "## Probability theory in ML\n",
    "\n",
    "Probability theory plays a fundamental role in machine learning by providing a framework for modeling uncertainty and making predictions based on data. We can tell when something happens, if this happens with a higher probability.\n",
    "\n",
    "### Modeling Uncertainty\n",
    "\n",
    "Machine learning often deals with uncertain outcomes, such as predicting whether an email is spam or not. Probability allows us to quantify this uncertainty. Models do not give a definite answer, instead they provide a probability score - e.g. 70% chance that the mail is spam\n",
    "\n",
    "### Probabilistic models\n",
    "\n",
    "Many machine learning models are probabilistic by nature, meaning they use probability distributions to make decisions.\n",
    "\n",
    "\n",
    "### Prior knowledge\n",
    "\n",
    "Models incorporate prior knowledge (experience E) to estimate the probability of something happening. This is how they \"learn\" to predict certain outcomes. \n",
    "\n",
    "### Other uses of probability theory in machine learning\n",
    "\n",
    "The concept of likelihood—a key probabilistic idea—is used to estimate the best parameters for a model and to optimise it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5181f36e",
   "metadata": {},
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "We know that Steve is a very shy and tidy person. What is higher:\n",
    "\n",
    "* Probability that he is a librarian?\n",
    "* Probability that he is a farmer?\n",
    "\n",
    "We know that Linda is actively engaged in the feminist movement. What is more probable:\n",
    "\n",
    "* Linda is a bank teller?\n",
    "* Linda is a bank teller and is active in the feminist movements?\n",
    "\n",
    "Let's see about Steve:\n",
    "\n",
    "We are given information that in the population there are 10 librarians and 200 farmers. What would you say now?\n",
    "\n",
    "And we got another piece of information:\n",
    "\n",
    "There is a 40% probability that librarian is shy and tidy, and 10% probability that farmer fits this description. What about now?\n",
    "\n",
    "### Bayes' Theorem in practice\n",
    "\n",
    "Bayes' Theorem helps us find the probability of an event given prior knowledge of related conditions. It is a simple and yet powerful equation, used widely in machine learning. Below equation is used as a basis for multiple machine learning models:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* P(A∣B) is the posterior probability: the probability of event A occurring given that B is true.\n",
    "* P(B∣A) is the likelihood: the probability of event B occurring given that A is true.\n",
    "* P(A) is the prior probability: the initial probability of event A.\n",
    "* P(B) is the marginal probability: the probability of event B occurring.\n",
    "\n",
    "Bayes' theorem provides a way to reason about probabilities in machine learning, especially in situations where we have to deal with uncertainty.\n",
    "\n",
    "This is a very quick algorithm with a lot of predictive power, used for example to:\n",
    "\n",
    "* Filter SPAM emails\n",
    "* Updating model beliefs given new information\n",
    "* In general in classification applications\n",
    "\n",
    "Going back to the example of Steve we know that\n",
    "\n",
    "    P(A|B) - is librarian given that he is shy and tidy\n",
    "    P(B|A) - is shy and tidy because he is a librarian\n",
    "    P(B) - is shy and tidy\n",
    "    P(A) - is librarian\n",
    "\n",
    "    P(B|A) - 40% of shy and tidy are librarians\n",
    "    P(B) - 10% of farmers is shy and tidy while 40% of librarians is shy and tidy\n",
    "    P(A) - 10 out of 210 people are librarians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11669f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(B|A) - is librarian because he is shy\n",
    "\n",
    "PBA = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13d16d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047619047619047616\n"
     ]
    }
   ],
   "source": [
    "#P(A) - is librarian\n",
    "PA = 10/(200+10)\n",
    "print(PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ff449cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "#P(~A) - is farmer\n",
    "PnA = 200/(200+10)\n",
    "print(PnA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1805c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11428571428571428\n"
     ]
    }
   ],
   "source": [
    "#P(B) - is shy (All shy people in the population)\n",
    "PB = 0.4*PA + 0.1*PnA\n",
    "print(PB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "272cdd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666669\n"
     ]
    }
   ],
   "source": [
    "#P(A|B) - is librarian given he is shy and tidy\n",
    "\n",
    "PAB = (0.4 * PA)/PB\n",
    "print(PAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f216bb",
   "metadata": {},
   "source": [
    "**There is only 16.7% probability that Steve is librarian!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de181da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195937206b264c1aba9ad0cd472f233d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='Num Librarians', min=1), IntSlider(value=200, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Function to calculate and visualize Bayes' Theorem for the given scenario\n",
    "def visualize_bayes_theorem(num_librarians=10, num_farmers=200, prob_shy_librarian=0.4, prob_shy_farmer=0.1):\n",
    "    # Calculate the total number of people\n",
    "    total_people = num_librarians + num_farmers\n",
    "    \n",
    "    # Calculate P(Librarian) and P(Farmer)\n",
    "    P_librarian = num_librarians / total_people\n",
    "    P_farmer = num_farmers / total_people\n",
    "    \n",
    "    # Calculate P(Shy|Librarian) and P(Shy|Farmer)\n",
    "    P_shy_given_librarian = prob_shy_librarian\n",
    "    P_shy_given_farmer = prob_shy_farmer\n",
    "    \n",
    "    # Calculate P(Shy) using the law of total probability\n",
    "    P_shy = (P_shy_given_librarian * P_librarian) + (P_shy_given_farmer * P_farmer)\n",
    "    \n",
    "    # Calculate P(Librarian|Shy) using Bayes' Theorem\n",
    "    P_librarian_given_shy = (P_shy_given_librarian * P_librarian) / P_shy\n",
    "    \n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    \n",
    "    # Bar plot showing probabilities\n",
    "    categories = ['Librarian', 'Farmer']\n",
    "    base_rates = [P_librarian, P_farmer]\n",
    "    shy_given_category = [P_shy_given_librarian, P_shy_given_farmer]\n",
    "    posterior = [P_librarian_given_shy, 1 - P_librarian_given_shy]\n",
    "    \n",
    "    # Plotting base rates\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.bar(categories, base_rates, color='blue', alpha=0.6, edgecolor='black')\n",
    "    plt.title('Base Rates (P(Librarian), P(Farmer))')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel('Probability')\n",
    "    \n",
    "    # Plotting conditional probabilities (P(Shy|Librarian) and P(Shy|Farmer))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.bar(categories, shy_given_category, color='green', alpha=0.6, edgecolor='black')\n",
    "    plt.title('P(Shy|Librarian) and P(Shy|Farmer)')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Plotting posterior probabilities (P(Librarian|Shy) and P(Farmer|Shy))\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.bar(categories, posterior, color='red', alpha=0.6, edgecolor='black')\n",
    "    plt.title('Posterior Probabilities (P(Librarian|Shy), P(Farmer|Shy))')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "#     plt.tight_layout(2)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive sliders and inputs\n",
    "interact(visualize_bayes_theorem,\n",
    "         num_librarians=widgets.IntSlider(min=1, max=100, step=1, value=10, description='Num Librarians'),\n",
    "         num_farmers=widgets.IntSlider(min=1, max=500, step=10, value=200, description='Num Farmers'),\n",
    "         prob_shy_librarian=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.4, description='P(Shy|Librarian)'),\n",
    "         prob_shy_farmer=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.1, description='P(Shy|Farmer)'));\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
